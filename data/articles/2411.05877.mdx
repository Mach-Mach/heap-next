---
title: Generative Adapter: Contextualizing Language Models in Parameters with A Single Forward Pass
date: 2024-11-12
tags: ['in-context learning', 'large language models', 'low-rank LM adapters', 'knowledge acquisition', 'fine-tuning', 'personalization', 'computational efficiency', 'self-supervised learning', 'prompting', 'inference overhead']
categories: ['cs.AI', 'cs.CL', 'cs.LG', 'stat.ML']
problem: GenerativeAdapter adaptation method
solution: ['accuracy compute tradeoff in adapting language models']
pdf_url: https://arxiv.org/pdf/2411.05877
arx_url: https://arxiv.org/abs/2411.05877
score: 5
authors: ['Tong Chen', 'Hao Fang', 'Patrick Xia', 'Xiaodong Liu', 'Benjamin Van Durme', 'Luke Zettlemoyer', 'Jianfeng Gao', 'Hao Cheng']
affiliations_aligned: ['University of Washington', 'Microsoft', 'Microsoft Research', 'Microsoft Research', 'Microsoft Research', 'University of Washington', 'Microsoft Research', 'Microsoft Research']
affiliations: ['Microsoft Research', 'Microsoft', 'University of Washington']
---


Large language models (LMs) are typically adapted to improve performance on new contexts (\eg text prompts that define new tasks or domains) through fine-tuning or prompting. However, there is an accuracy compute tradeoff -- fine-tuning incurs significant training cost and prompting increases inference overhead. We introduce $GenerativeAdapter$, an effective and efficient adaptation method that directly maps new contexts to low-rank LM adapters, thereby significantly reducing inference overhead with no need for finetuning. The adapter generator is trained via self-supervised learning, and can be used to adapt a single frozen LM for any new task simply by mapping the associated task or domain context to a new adapter. We apply $GenerativeAdapter$ to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models in three adaption scenarios: knowledge acquisition from documents, learning from demonstrations, and personalization for users. In StreamingQA, our approach is effective in injecting knowledge into the LM's parameters, achieving a 63.5% improvement in F1 score over the model with supervised fine-tuning (from $19.5$ to $31.5$) for contexts as long as 32K tokens. In the MetaICL in-context learning evaluation, our method achieves an average accuracy of $44.9$ across 26 tasks, outperforming the base model. On MSC, our method proves to be highly competitive in memorizing user information from conversations with a 4x reduction in computation and memory costs compared to prompting with full conversation history. Together, these results suggest that $GenerativeAdapter$ should allow for general adaption to a wide range of different contexts.