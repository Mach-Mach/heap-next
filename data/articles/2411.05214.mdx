---
title: STAND-Guard: A Small Task-Adaptive Content Moderation Model
date: 2024_11_11
tags: ['binary classification', 'task-adaptive models', 'instruct tuning', 'large language models', 'small language models', 'cross-task fine-tuning', 'model efficacy', 'content moderation']
categories: ['cs.CL']
problem: STAND-Guard model
solution: ['need for adaptable content moderation models']
pdf_url: https://arxiv.org/pdf/2411.05214
arx_url: https://arxiv.org/abs/2411.05214
score: 5
authors: ['Minjia Wang', 'Pingping Lin', 'Siqi Cai', 'Shengnan An', 'Shengjie Ma', 'Zeqi Lin', 'Congrui Huang', 'Bixiong Xu']
affiliations_aligned: ['Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft']
affiliations: ['Microsoft']
---


Content moderation, the process of reviewing and monitoring the safety of generated content, is important for development of welcoming online platforms and responsible large language models. Content moderation contains various tasks, each with its unique requirements tailored to specific scenarios. Therefore, it is crucial to develop a model that can be easily adapted to novel or customized content moderation tasks accurately without extensive model tuning. This paper presents STAND-GUARD, a Small Task-Adaptive coNtent moDeration model. The basic motivation is: by performing instruct tuning on various content moderation tasks, we can unleash the power of small language models (SLMs) on unseen (out-of-distribution) content moderation tasks. We also carefully study the effects of training tasks and model size on the efficacy of cross-task fine-tuning mechanism. Experiments demonstrate STAND-Guard is comparable to GPT-3.5-Turbo across over 40 public datasets, as well as proprietary datasets derived from real-world business scenarios. Remarkably, STAND-Guard achieved nearly equivalent results to GPT-4-Turbo on unseen English binary classification tasks