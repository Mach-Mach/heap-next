---
title: 'PIAST: A Multimodal Piano Dataset with Audio, Symbolic and Text'
date: 2024-11-08
tags: ['piano music', 'audio', 'beat tracking', 'semantic tags', 'text labels', 'datasets', 'Music Information Retrieval', 'MIDI', 'retrieval', 'music tagging']
categories: ['cs.SD', 'eess.AS', 'cs.MM', 'cs.AI']
problem: P
solution: ['lack of datasets for piano solo music with text labels']
pdf_url: https://arxiv.org/pdf/2411.02551
arx_url: https://arxiv.org/abs/2411.02551
score: 4
authors: ['Hayeon Bang', 'Eunjin Choi', 'Megan Finch', 'Seungheon Doh', 'Seolhee Lee', 'Gyeong-Hoon Lee', 'Juhan Nam']
affiliations_aligned: ['Graduate School of Culture Technology, KAIST, South Korea', 'Graduate School of Culture Technology, KAIST, South Korea', 'Graduate School of Culture Technology, KAIST, South Korea', 'Graduate School of Culture Technology, KAIST, South Korea', 'Graduate School of Culture Technology, KAIST, South Korea', 'Graduate School of Culture Technology, KAIST, South Korea', 'Graduate School of Culture Technology, KAIST, South Korea']
affiliations: ['Graduate School of Culture Technology, KAIST, South Korea']
---


While piano music has become a significant area of study in Music Information Retrieval (MIR), there is a notable lack of datasets for piano solo music with text labels. To address this gap, we present PIAST (PIano dataset with Audio, Symbolic, and Text), a piano music dataset. Utilizing a piano-specific taxonomy of semantic tags, we collected 9,673 tracks from YouTube and added human annotations for 2,023 tracks by music experts, resulting in two subsets: PIAST-YT and PIAST-AT. Both include audio, text, tag annotations, and transcribed MIDI utilizing state-of-the-art piano transcription and beat tracking models. Among many possible tasks with the multi-modal dataset, we conduct music tagging and retrieval using both audio and MIDI data and report baseline performances to demonstrate its potential as a valuable resource for MIR research.