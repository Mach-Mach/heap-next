---
title: 'LoRA-Contextualizing Adaptation of Large Multimodal Models for Long Document Understanding'
date: 2024-11-02
tags: ['large multimodal models', 'efficiency limitations', 'retrieval-augmented generation', 'question answering', 'empirical results', 'text-rich image understanding', 'LoRA-Contextualizing Adaptation', 'long-document understanding', 'document parsers', 'performance limitations', 'public benchmarks', 'LoCAL framework', 'evidence page retrieval', 'multimodal retrievers']
categories: ['cs.CV']
problem: L
solution: ['complex multi-page visually-rich documents']
pdf_url: http://arxiv.org/pdf/2411.01106v1
arx_url: http://arxiv.org/abs/2411.01106v1
score: 4
authors: ['Jian Chen', 'Ruiyi Zhang', 'Yufan Zhou', 'Tong Yu', 'Franck Dernoncourt', 'Jiuxiang Gu', 'Ryan A. Rossi', 'Changyou Chen', 'Tong Sun', 'Ryan Rossi']
affiliations_aligned: ['Adobe Research', 'Adobe Research', 'Adobe Research', 'Adobe Research', 'Adobe Research', 'Adobe Research', '', 'University at Buffalo', 'Adobe Research', 'Adobe Research']
affiliations: ['', 'Adobe Research', 'University at Buffalo']
---


Large multimodal models (LMMs) have recently shown great progress in text-rich image understanding, yet they still struggle with complex, multi-page, visually-rich documents. Traditional methods using document parsers for retrieval-augmented generation suffer from performance and efficiency limitations, while directly presenting all pages to LMMs leads to inefficiencies, especially with lengthy documents. In this work, we present a novel framework named LoRA-Contextualizing Adaptation of Large multimodal models (LoCAL), which broadens the capabilities of any LMM to support long-document understanding. We demonstrate that LMMs can effectively serve as multimodal retrievers, fetching relevant pages to answer user questions based on these pages. LoCAL is implemented with two specific LMM adapters: one for evidence page retrieval and another for question answering. Empirical results show state-of-the-art performance on public benchmarks, demonstrating the effectiveness of LoCAL.