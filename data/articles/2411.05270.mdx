---
title: Seeing Through the Fog: A Cost-Effectiveness Analysis of Hallucination Detection Systems
date: 2024_11_11
tags: ['cost-effectiveness metrics', 'question answering', 'hallucination detection systems', 'Large Language Models', 'automatic summarization', 'automated identification', 'diagnostic odds ratio', 'hybrid systems', 'AI reliability']
categories: ['cs.CL', 'cs.AI']
problem: cost-effectiveness analysis of hallucination detection systems
solution: ['hallucination detection in AI systems']
pdf_url: https://arxiv.org/pdf/2411.05270
arx_url: https://arxiv.org/abs/2411.05270
score: 5
authors: ['Alexander Thomas', 'Seth Rosen', 'Vishnu Vettrivel']
affiliations_aligned: ['', '', '']
affiliations: ['']
---


This paper presents a comparative analysis of hallucination detection systems for AI, focusing on automatic summarization and question answering tasks for Large Language Models (LLMs). We evaluate different hallucination detection systems using the diagnostic odds ratio (DOR) and cost-effectiveness metrics. Our results indicate that although advanced models can perform better they come at a much higher cost. We also demonstrate how an ideal hallucination detection system needs to maintain performance across different model sizes. Our findings highlight the importance of choosing a detection system aligned with specific application needs and resource constraints. Future research will explore hybrid systems and automated identification of underperforming components to enhance AI reliability and efficiency in detecting and mitigating hallucinations.