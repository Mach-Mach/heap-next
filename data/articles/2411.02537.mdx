---
title: 'INQUIRE: A Natural World Text-to-Image Retrieval Benchmark'
date: 2024-11-08
tags: ['multimodal vision-language models', 'biodiversity research', 'expert-level queries', 'iNaturalist 2024 dataset', 'text-to-image retrieval', 'species identification', 'multimodal models', 'ecological challenges', 'domain expertise', 'image understanding', 'retrieval tasks']
categories: ['cs.AI', 'cs.CL', 'cs.CV', 'cs.IR']
problem: I
solution: ['challenge in multimodal vision-language models on expert-level queries']
pdf_url: https://arxiv.org/pdf/2411.02537
arx_url: https://arxiv.org/abs/2411.02537
score: 5
authors: ['Edward Vendrow', 'Omiros Pantazis', 'Alexander Shepard', 'Gabriel Brostow', 'Kate E. Jones', 'Oisin Mac Aodha', 'Sara Beery', 'Grant Van Horn']
affiliations_aligned: ['Massachusetts Institute of Technology', 'University College London', 'iNaturalist', 'University College London', 'University College London', 'University of Edinburgh', 'Massachusetts Institute of Technology', 'University of Massachusetts Amherst']
affiliations: ['University of Edinburgh', 'iNaturalist', 'University of Massachusetts Amherst', 'Massachusetts Institute of Technology', 'University College London']
---


We introduce INQUIRE, a text-to-image retrieval benchmark designed to challenge multimodal vision-language models on expert-level queries. INQUIRE includes iNaturalist 2024 (iNat24), a new dataset of five million natural world images, along with 250 expert-level retrieval queries. These queries are paired with all relevant images comprehensively labeled within iNat24, comprising 33,000 total matches. Queries span categories such as species identification, context, behavior, and appearance, emphasizing tasks that require nuanced image understanding and domain expertise. Our benchmark evaluates two core retrieval tasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2) INQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed evaluation of a range of recent multimodal models demonstrates that INQUIRE poses a significant challenge, with the best models failing to achieve an mAP@50 above 50%. In addition, we show that reranking with more powerful multimodal models can enhance retrieval performance, yet there remains a significant margin for improvement. By focusing on scientifically-motivated ecological challenges, INQUIRE aims to bridge the gap between AI capabilities and the needs of real-world scientific inquiry, encouraging the development of retrieval systems that can assist with accelerating ecological and biodiversity research. Our dataset and code are available at https://inquire-benchmark.github.io