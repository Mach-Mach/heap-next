---
title: Can Language Models Learn to Skip Steps?
date: 2024_11_04
tags: ['efficiency', 'human-like reasoning', 'language models', 'generalization capabilities', 'step-skipping behavior', 'AI models', 'cognitive load']
categories: ['cs.CL']
problem: controlled framework that stimulates step-skipping behavior
solution: ['ability to skip steps in reasoning']
pdf_url: http://arxiv.org/pdf/2411.01855v1
arx_url: http://arxiv.org/abs/2411.01855v1
score: 5
authors: ['Tengxiao Liu', 'Qipeng Guo', 'Xiangkun Hu', 'Cheng Jiayang', 'Yue Zhang', 'Xipeng Qiu', 'Zheng Zhang']
affiliations_aligned: ['UC Santa Barbara', 'Shanghai AI Laboratory', 'Amazon AWS AI', 'Amazon AWS AI', 'Westlake University', 'Fudan University', 'Amazon AWS AI']
affiliations: ['Shanghai AI Laboratory', 'Amazon AWS AI', 'Westlake University', 'UC Santa Barbara', 'Fudan University']
---


Trained on vast corpora of human language, language models demonstrate
emergent human-like reasoning abilities. Yet they are still far from true
intelligence, which opens up intriguing opportunities to explore the parallels
of humans and model behaviors. In this work, we study the ability to skip steps
in reasoning - a hallmark of human expertise developed through practice. Unlike
humans, who may skip steps to enhance efficiency or to reduce cognitive load,
models do not inherently possess such motivations to minimize reasoning steps.
To address this, we introduce a controlled framework that stimulates
step-skipping behavior by iteratively refining models to generate shorter and
accurate reasoning paths. Empirical results indicate that models can develop
the step skipping ability under our guidance. Moreover, after fine-tuning on
expanded datasets that include both complete and skipped reasoning sequences,
the models can not only resolve tasks with increased efficiency without
sacrificing accuracy, but also exhibit comparable and even enhanced
generalization capabilities in out-of-domain scenarios. Our work presents the
first exploration into human-like step-skipping ability and provides fresh
perspectives on how such cognitive abilities can benefit AI models.