---
title: ReMatching Dynamic Reconstruction Flow
date: 2024-11-01
tags: ['model priors', 'dynamic representations', 'dynamic reconstruction models', 'dynamic scene reconstruction', 'velocity-field-based priors', 'generalization quality', 'reconstruction accuracy', 'deformation priors', 'computer vision']
categories: ['cs.CV', 'eess.IV', 'cs.LG']
problem: ReMatching framework
solution: ['high-quality reconstructions from unseen viewpoints and timestamps']
pdf_url: http://arxiv.org/pdf/2411.00705v1
arx_url: http://arxiv.org/abs/2411.00705v1
score: 4
authors: ['Sara Oblak', 'Despoina Paschalidou', 'Sanja Fidler', 'Matan Atzmon']
affiliations_aligned: ['NVIDIA', 'NVIDIA', 'University of Toronto', 'Vector Institute']
affiliations: ['University of Toronto', 'Vector Institute', 'NVIDIA']
---


Reconstructing dynamic scenes from image inputs is a fundamental computer vision task with many downstream applications. Despite recent advancements, existing approaches still struggle to achieve high-quality reconstructions from unseen viewpoints and timestamps. This work introduces the ReMatching framework, designed to improve generalization quality by incorporating deformation priors into dynamic reconstruction models. Our approach advocates for velocity-field-based priors, for which we suggest a matching procedure that can seamlessly supplement existing dynamic reconstruction pipelines. The framework is highly adaptable and can be applied to various dynamic representations. Moreover, it supports integrating multiple types of model priors and enables combining simpler ones to create more complex classes. Our evaluations on popular benchmarks involving both synthetic and real-world dynamic scenes demonstrate a clear improvement in reconstruction accuracy of current state-of-the-art models.