---
title: Game-theoretic LLM: Agent Workflow for Negotiation Games
date: 2024-11-12
tags: ['game theory', 'negotiation scenarios', 'Nash Equilibria', 'AI agents', 'strategic decision-making', 'large language models', 'meta-strategic considerations']
categories: ['cs.AI', 'cs.GT', 'cs.MA', 'cs.CL', 'cs.LG']
problem: game-theoretic workflows for LLMs
solution: ['deviation from rational strategies in LLMs']
pdf_url: https://arxiv.org/pdf/2411.05990
arx_url: https://arxiv.org/abs/2411.05990
score: 4
authors: ['Wenyue Hua', 'Ollie Liu', 'Lingyao Li', 'Alfonso Amayuelas', 'Julie Chen', 'Lucas Jiang', 'Mingyu Jin', 'Lizhou Fan', 'Fei Sun', 'William Wang', 'Xintong Wang', 'Yongfeng Zhang']
affiliations_aligned: ['University of California, Santa Barbara', 'University of Southern California', 'University of South Florida', 'University of California, Santa Barbara', 'Independent Researcher', 'Independent Researcher', 'University of California, Santa Barbara', 'Harvard University', 'Institute of Computing Technology', 'University of California, Santa Barbara', 'University of California, Santa Barbara', 'Rutgers University, New Brunswick']
affiliations: ['University of Southern California', 'University of South Florida', 'Rutgers University, New Brunswick', 'Independent Researcher', 'Institute of Computing Technology', 'University of California, Santa Barbara', 'Harvard University']
---


This paper investigates the rationality of large language models (LLMs) in strategic decision-making contexts, specifically within the framework of game theory. We evaluate several state-of-the-art LLMs across a spectrum of complete-information and incomplete-information games. Our findings reveal that LLMs frequently deviate from rational strategies, particularly as the complexity of the game increases with larger payoff matrices or deeper sequential trees.   To address these limitations, we design multiple game-theoretic workflows that guide the reasoning and decision-making processes of LLMs. These workflows aim to enhance the models' ability to compute Nash Equilibria and make rational choices, even under conditions of uncertainty and incomplete information. Experimental results demonstrate that the adoption of these workflows significantly improves the rationality and robustness of LLMs in game-theoretic tasks. Specifically, with the workflow, LLMs exhibit marked improvements in identifying optimal strategies, achieving near-optimal allocations in negotiation scenarios, and reducing susceptibility to exploitation during negotiations. Furthermore, we explore the meta-strategic considerations of whether it is rational for agents to adopt such workflows, recognizing that the decision to use or forgo the workflow constitutes a game-theoretic issue in itself.   Our research contributes to a deeper understanding of LLMs' decision-making capabilities in strategic contexts and provides insights into enhancing their rationality through structured workflows. The findings have implications for the development of more robust and strategically sound AI agents capable of navigating complex interactive environments. Code and data supporting this study are available at \url{https://github.com/Wenyueh/game_theory}.