---
title: 'Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models'
date: 2024-11-03
tags: ['weight decay', 'AdamW optimizer', 'foundation models', 'vision benchmarks', 'regularization techniques', 'out-of-distribution robustness', 'language benchmarks', 'in-distribution generalization', 'parameter space exploration']
categories: ['cs.CL', 'cs.CV', 'cs.LG']
problem: Selective Projection Decay technique
solution: robustness and generalization issues when fine-tuning foundation models
pdf_url: http://arxiv.org/pdf/2411.01713v1
arx_url: http://arxiv.org/abs/2411.01713v1
score: 4
authors: ['Junjiao Tian', 'Chengyue Huang', 'Zsolt Kira']
affiliations_aligned: ['Georgia Institute of Technology', 'Georgia Institute of Technology', 'Georgia Institute of Technology']
affiliations: ['Georgia Institute of Technology']
---


Modern optimizers such as AdamW, equipped with momentum and adaptive learning rate, are designed to escape local minima and explore the vast parameter space. This exploration is beneficial for finding good loss basins when training from scratch. It is not necessarily ideal when resuming from a powerful foundation model because it can lead to large deviations from the pre-trained initialization and, consequently, worse robustness and generalization. At the same time, strong regularization on all parameters can lead to under-fitting. We hypothesize that selectively regularizing the parameter space is the key to fitting and retraining the pre-trained knowledge. This paper proposes a new weight decay technique, Selective Projection Decay (SPD), that selectively imposes a strong penalty on certain layers while allowing others to change freely. Intuitively, SPD expands and contracts the parameter search space for layers with consistent and inconsistent loss reduction, respectively. Experimentally, when equipped with SPD, Adam consistently provides better in-distribution generalization and out-of-distribution robustness performance on multiple popular vision and language benchmarks. Code available at~\url{https://github.com/GT-RIPL/Selective-Projection-Decay.git}