---
title: 'From Pixels to Prose: Advancing Multi-Modal Language Models for Remote Sensing'
date: 2024-11-12
tags: ['text-to-image retrieval', 'satellite imagery', 'self-supervised learning', 'scene description', 'urban planning', 'contrastive learning', 'image-to-text generation', 'Transformer models', 'environmental monitoring', 'data quality', 'scalability', 'datasets', 'remote sensing', 'cross-modal integration', 'dual-encoder architectures', 'computational demands', 'object detection', 'multi-modal language models', 'disaster response', 'domain adaptation', 'visual question answering', 'change detection']
categories: ['cs.AI', 'cs.CV', 'cs.LG']
problem: a
solution: ['challenges of remote sensing data']
pdf_url: https://arxiv.org/pdf/2411.05826
arx_url: https://arxiv.org/abs/2411.05826
score: 5
authors: ['Xintian Sun', 'Benji Peng', 'Charles Zhang', 'Fei Jin', 'Qian Niu', 'Junyu Liu', 'Keyu Chen', 'Ming Li', 'Pohsun Feng', 'Ziqian Bi', 'Ming Liu', 'Yichao Zhang']
affiliations_aligned: ['Simon Fraser University, Canada', 'AppCubic, USA', 'AppCubic, USA', 'Depth LLC, USA', 'Kyoto University, Japan', 'Kyoto University, Japan', 'Georgia Institute of Technology, USA', 'Georgia Institute of Technology, USA', 'National Taiwan Normal University, ROC', 'Purdue University, USA', 'Purdue University, USA', 'The University of Texas at Dallas, USA']
affiliations: ['Simon Fraser University, Canada', 'AppCubic, USA', 'Depth LLC, USA', 'The University of Texas at Dallas, USA', 'Purdue University, USA', 'National Taiwan Normal University, ROC', 'Kyoto University, Japan', 'Georgia Institute of Technology, USA']
---


Remote sensing has evolved from simple image acquisition to complex systems capable of integrating and processing visual and textual data. This review examines the development and application of multi-modal language models (MLLMs) in remote sensing, focusing on their ability to interpret and describe satellite imagery using natural language. We cover the technical underpinnings of MLLMs, including dual-encoder architectures, Transformer models, self-supervised and contrastive learning, and cross-modal integration. The unique challenges of remote sensing data--varying spatial resolutions, spectral richness, and temporal changes--are analyzed for their impact on MLLM performance. Key applications such as scene description, object detection, change detection, text-to-image retrieval, image-to-text generation, and visual question answering are discussed to demonstrate their relevance in environmental monitoring, urban planning, and disaster response. We review significant datasets and resources supporting the training and evaluation of these models. Challenges related to computational demands, scalability, data quality, and domain adaptation are highlighted. We conclude by proposing future research directions and technological advancements to further enhance MLLM utility in remote sensing.