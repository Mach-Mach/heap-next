---
title: Explaining and Improving Contrastive Decoding by Extrapolating the   Probabilities of a Huge and Hypothetical LM
date: 2024-11-03
tags: ['perplexity', 'text generation', 'contrastive decoding', 'language models', 'factuality', 'commonsense QA', 'asymptotic probability decoding']
categories: ['cs.CL']
problem: asymptotic probability decoding
solution: ['limitations of contrastive decoding']
pdf_url: http://arxiv.org/pdf/2411.01610v1
arx_url: http://arxiv.org/abs/2411.01610v1
score: 5
authors: ['Haw-Shiuan Chang', 'Nanyun Peng', 'Mohit Bansal', 'Anil Ramakrishna', 'Tagyoung Chung']
affiliations_aligned: ['UMass Amherst CICS', 'Amazon AGI Foundations', 'Amazon AGI Foundations', 'Amazon AGI Foundations', 'Amazon AGI Foundations']
affiliations: ['Amazon AGI Foundations', 'UMass Amherst CICS']
---


Contrastive decoding (CD) (Li et al., 2023) improves the next-token distribution of a large expert language model (LM) using a small amateur LM. Although CD is applied to various LMs and domains to enhance open-ended text generation, it is still unclear why CD often works well, when it could fail, and how we can make it better. To deepen our understanding of CD, we first theoretically prove that CD could be viewed as linearly extrapolating the next-token logits from a huge and hypothetical LM. We also highlight that the linear extrapolation could make CD unable to output the most obvious answers that have already been assigned high probabilities by the amateur LM.   To overcome CD's limitation, we propose a new unsupervised decoding method called $\mathbf{A}$symptotic $\mathbf{P}$robability $\mathbf{D}$ecoding (APD). APD explicitly extrapolates the probability curves from the LMs of different sizes to infer the asymptotic probabilities from an infinitely large LM without inducing more inference costs than CD. In FactualityPrompts, an open-ended text generation benchmark, sampling using APD significantly boosts factuality in comparison to the CD sampling and its variants, and achieves state-of-the-art results for Pythia 6.9B and OPT 6.7B. Furthermore, in five commonsense QA datasets, APD is often significantly better than CD and achieves a similar effect of using a larger LLM. For example, the perplexity of APD on top of Pythia 6.9B is even lower than the perplexity of Pythia 12B in CommonsenseQA and LAMBADA.