---
title: 'Integrating Object Detection Modality into Visual Language Model for Enhanced Autonomous Driving Agent'
date: 2024-11-12
tags: ['object detection', 'Llama-Adapter architecture', 'ChatGPT scores', 'environmental awareness', 'DriveLM visual question answering challenge', 'CIDEr metrics', 'visual language models', 'multi-view processing', 'CLIP perception network', 'safety enhancement', 'autonomous driving', 'YOLOS-based detection network', 'BLEU scores']
categories: ['cs.AI', 'cs.CV', 'cs.RO']
problem: n
solution: ['limitations in object detection and localisation']
pdf_url: https://arxiv.org/pdf/2411.05898
arx_url: https://arxiv.org/abs/2411.05898
score: 4
authors: ['Linfeng He', 'Yiming Sun', 'Sihao Wu', 'Jiaxu Liu', 'Xiaowei Huang']
affiliations_aligned: ['Department of Computer Science, University of Liverpool, United Kingdom', 'School of Computer Science, University of Nottingham, United Kingdom', 'Department of Computer Science, University of Liverpool, United Kingdom', 'Department of Computer Science, University of Liverpool, United Kingdom', 'Department of Computer Science, University of Liverpool, United Kingdom']
affiliations: ['School of Computer Science, University of Nottingham, United Kingdom', 'Department of Computer Science, University of Liverpool, United Kingdom']
---


In this paper, we propose a novel framework for enhancing visual comprehension in autonomous driving systems by integrating visual language models (VLMs) with additional visual perception module specialised in object detection. We extend the Llama-Adapter architecture by incorporating a YOLOS-based detection network alongside the CLIP perception network, addressing limitations in object detection and localisation. Our approach introduces camera ID-separators to improve multi-view processing, crucial for comprehensive environmental awareness. Experiments on the DriveLM visual question answering challenge demonstrate significant improvements over baseline models, with enhanced performance in ChatGPT scores, BLEU scores, and CIDEr metrics, indicating closeness of model answer to ground truth. Our method represents a promising step towards more capable and interpretable autonomous driving systems. Possible safety enhancement enabled by detection modality is also discussed.