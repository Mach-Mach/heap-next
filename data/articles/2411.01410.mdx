---
title: PageRank Bandits for Link Prediction
date: 2024_11_03
tags: ['reward formulation', 'knowledge graph completion', 'exploitation versus exploration', 'collaborative exploitation', 'PageRank', 'link prediction', 'supervised learning', 'sequential decision-making', 'graph learning', 'contextual bandits', 'Graph Neural Networks', 'theoretical performance guarantee', 'empirical evaluation', 'similarity metrics', 'recommender systems']
categories: ['cs.AI', 'cs.LG', 'cs.SI']
problem: PRB (PageRank Bandits) algorithm
solution: ['challenges in link prediction']
pdf_url: http://arxiv.org/pdf/2411.01410v1
arx_url: http://arxiv.org/abs/2411.01410v1
score: 4
authors: ['Yikun Ban', 'Jiaru Zou', 'Zihao Li', 'Yunzhe Qi', 'Dongqi Fu', 'Jian Kang', 'Hanghang Tong', 'Jingrui He']
affiliations_aligned: ['University of Illinois Urbana-Champaign', 'University of Illinois Urbana-Champaign', 'University of Illinois Urbana-Champaign', 'University of Illinois Urbana-Champaign', 'Meta AI', 'University of Rochester', 'University of Illinois Urbana-Champaign', 'University of Illinois Urbana-Champaign']
affiliations: ['University of Rochester', 'Meta AI', 'University of Illinois Urbana-Champaign']
---


Link prediction is a critical problem in graph learning with broad
applications such as recommender systems and knowledge graph completion.
Numerous research efforts have been directed at solving this problem, including
approaches based on similarity metrics and Graph Neural Networks (GNN).
However, most existing solutions are still rooted in conventional supervised
learning, which makes it challenging to adapt over time to changing customer
interests and to address the inherent dilemma of exploitation versus
exploration in link prediction. To tackle these challenges, this paper
reformulates link prediction as a sequential decision-making process, where
each link prediction interaction occurs sequentially. We propose a novel fusion
algorithm, PRB (PageRank Bandits), which is the first to combine contextual
bandits with PageRank for collaborative exploitation and exploration. We also
introduce a new reward formulation and provide a theoretical performance
guarantee for PRB. Finally, we extensively evaluate PRB in both online and
offline settings, comparing it with bandit-based and graph-based methods. The
empirical success of PRB demonstrates the value of the proposed fusion
approach. Our code is released at https://github.com/jiaruzouu/PRB.