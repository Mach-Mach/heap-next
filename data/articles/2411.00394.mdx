---
title: Right this way: Can VLMs Guide Us to See More to Answer Questions?
date: 2024-11-01
tags: ['performance improvement', 'visually impaired assistance', 'synthetic training data', 'information sufficiency', 'dataset', 'Vision Language Models', 'Visual Question Answering']
categories: ['cs.CV', 'cs.AI', 'cs.LG']
problem: automated framework for generating synthetic training data
solution: ['insufficient visual information in question-answering']
pdf_url: http://arxiv.org/pdf/2411.00394v1
arx_url: http://arxiv.org/abs/2411.00394v1
score: 5
authors: ['Li Liu', 'Diji Yang', 'Sijia Zhong', 'Kalyana Suma Sree Tholeti', 'Lei Ding', 'Yi Zhang', 'Leilani H. Gilpin']
affiliations_aligned: ['University of California, Santa Cruz', 'University of California, Santa Cruz', 'University of California, Santa Cruz', 'University of California, Santa Cruz', 'University of California, Santa Cruz', 'University of California, Santa Cruz', 'University of California, Santa Cruz']
affiliations: ['University of California, Santa Cruz']
---


In question-answering scenarios, humans can assess whether the available information is sufficient and seek additional information if necessary, rather than providing a forced answer. In contrast, Vision Language Models (VLMs) typically generate direct, one-shot responses without evaluating the sufficiency of the information. To investigate this gap, we identify a critical and challenging task in the Visual Question Answering (VQA) scenario: can VLMs indicate how to adjust an image when the visual information is insufficient to answer a question? This capability is especially valuable for assisting visually impaired individuals who often need guidance to capture images correctly. To evaluate this capability of current VLMs, we introduce a human-labeled dataset as a benchmark for this task. Additionally, we present an automated framework that generates synthetic training data by simulating ``where to know'' scenarios. Our empirical results show significant performance improvements in mainstream VLMs when fine-tuned with this synthetic data. This study demonstrates the potential to narrow the gap between information assessment and acquisition in VLMs, bringing their performance closer to humans.