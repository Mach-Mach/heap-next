---
title: How Good is Your Wikipedia?
date: 2024_11_11
tags: ['multilingual NLP', 'quality filtering techniques', 'language-specific data quality', 'performance', 'low-resource languages', 'resource-efficient training', 'data quality', 'Wikipedia']
categories: ['cs.CL']
problem: quality filtering techniques for resource-efficient training
solution: ['data quality of Wikipedia in a non-English setting']
pdf_url: https://arxiv.org/pdf/2411.05527
arx_url: https://arxiv.org/abs/2411.05527
score: 5
authors: ['Kushal Tatariya', 'Artur Kulmizev', 'Wessel Poelman', 'Esther Ploeger', 'Marcel Bollmann', 'Johannes Bjerva', 'Jiaming Luo', 'Heather Lent', 'Miryam de Lhoneux']
affiliations_aligned: ['Department of Computer Science, KU Leuven', 'Department of Computer Science, KU Leuven', 'Department of Computer Science, KU Leuven', 'Department of Computer Science, Aalborg University', 'Department of Computer and Information Science, Linköping University', 'Department of Computer Science, Aalborg University', 'Google Translate', 'Department of Computer Science, Aalborg University', 'Department of Computer Science, KU Leuven']
affiliations: ['Department of Computer Science, Aalborg University', 'Department of Computer and Information Science, Linköping University', 'Department of Computer Science, KU Leuven', 'Google Translate']
---


Wikipedia's perceived high quality and broad language coverage have established it as a fundamental resource in multilingual NLP. In the context of low-resource languages, however, these quality assumptions are increasingly being scrutinised. This paper critically examines the data quality of Wikipedia in a non-English setting by subjecting it to various quality filtering techniques, revealing widespread issues such as a high percentage of one-line articles and duplicate articles. We evaluate the downstream impact of quality filtering on Wikipedia and find that data quality pruning is an effective means for resource-efficient training without hurting performance, especially for low-resource languages. Moreover, we advocate for a shift in perspective from seeking a general definition of data quality towards a more language- and task-specific one. Ultimately, we aim for this study to serve as a guide to using Wikipedia for pretraining in a multilingual setting.