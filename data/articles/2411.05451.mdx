---
title: WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models
date: 2024_11_11
tags: ['zero-shot generalization', 'Agentic Process Automation', 'workflow orchestration', 'data-centric framework', 'API', 'large language models', 'workflow generation', 'fine-tuning dataset', 'Robotic Process Automation']
categories: ['cs.CL', 'cs.SE', 'cs.AI']
problem: WorkflowLLM framework to enhance workflow orchestration capability of large language models
solution: ['limited capability of existing large language models in workflow orchestration']
pdf_url: https://arxiv.org/pdf/2411.05451
arx_url: https://arxiv.org/abs/2411.05451
score: 4
authors: ['Shengda Fan', 'Xin Cong', 'Yuepeng Fu', 'Zhong Zhang', 'Shuyan Zhang', 'Yuanwei Liu', 'Yesai Wu', 'Yankai Lin', 'Zhiyuan Liu', 'Maosong Sun']
affiliations_aligned: ['Renmin University of China', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'The University of Manchester', 'Wuhan University', 'Tsinghua University', 'Renmin University of China', 'Tsinghua University', 'Tsinghua University']
affiliations: ['Renmin University of China', 'The University of Manchester', 'Tsinghua University', 'Wuhan University']
---


Recent advancements in large language models (LLMs) have driven a revolutionary paradigm shift in process automation from Robotic Process Automation to Agentic Process Automation by automating the workflow orchestration procedure based on LLMs. However, existing LLMs (even the advanced OpenAI GPT-4o) are confined to achieving satisfactory capability in workflow orchestration. To address this limitation, we present WorkflowLLM, a data-centric framework elaborately designed to enhance the capability of LLMs in workflow orchestration. It first constructs a large-scale fine-tuning dataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83 applications across 28 categories. Specifically, the construction process can be divided into three phases: (1) Data Collection: we collect real-world workflow data from Apple Shortcuts and RoutineHub, transcribing them into Python-style code. We further equip them with generated hierarchical thought via ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task queries to enrich the diversity and complexity of workflows. (3) Workflow Generation: we leverage an annotator model trained on collected data to generate workflows for synthesized queries. Finally, we merge the synthetic samples that pass quality confirmation with the collected samples to obtain the WorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain WorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong capacity to orchestrate complex workflows, while also achieving notable generalization performance on previously unseen APIs. Additionally, WorkflowBench exhibits robust zero-shot generalization capabilities on an out-of-distribution task planning dataset, T-Eval. Our data and code are available at https://github.com/OpenBMB/WorkflowLLM.