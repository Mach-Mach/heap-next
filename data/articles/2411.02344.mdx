---
title: 'Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning'
date: 2024-11-04
tags: ['exact match accuracy', 'arithmetic expression datasets', 'chain-of-thought tokens', 'longest increasing subsequence datasets', 'performance improvement', 'integer multiplication task', 'entropy of intermediate representations', 'arithmetic reasoning', 'representation collapse', 'Decoder-only Transformers', 'dummy pause tokens', 'complex reasoning tasks', 'Sequential Variance-Covariance Regularization']
categories: ['cs.CL', 'cs.LG']
problem: representation collapse in intermediate layers limiting reasoning capabilities
solution: Sequential Variance-Covariance Regularization (Seq-VCR)
pdf_url: http://arxiv.org/pdf/2411.02344v1
arx_url: http://arxiv.org/abs/2411.02344v1
score: 6
authors: ['Md Rifat Arefin', 'Gopeshh Subbaraj', 'Nicolas Gontier', 'Yann LeCun', 'Irina Rish', 'Ravid Shwartz-Ziv', 'Christopher Pal']
affiliations_aligned: ['Université de Montréal, Mila', 'Université de Montréal, Mila', 'ServiceNow', 'Meta FAIR', 'Université de Montréal, Mila', 'New York University', 'ServiceNow, Polytechnique Montreal']
affiliations: ['ServiceNow, Polytechnique Montreal', 'Université de Montréal, Mila', 'Meta FAIR', 'New York University', 'ServiceNow']
---


Decoder-only Transformers often struggle with complex reasoning tasks, particularly arithmetic reasoning requiring multiple sequential operations. In this work, we identify representation collapse in the model's intermediate layers as a key factor limiting their reasoning capabilities. To address this, we propose Sequential Variance-Covariance Regularization (Seq-VCR), which enhances the entropy of intermediate representations and prevents collapse. Combined with dummy pause tokens as substitutes for chain-of-thought (CoT) tokens, our method significantly improves performance in arithmetic reasoning problems. In the challenging $5 \times 5$ integer multiplication task, our approach achieves $99.5\%$ exact match accuracy, outperforming models of the same size (which yield $0\%$ accuracy) and GPT-4 with five-shot CoT prompting ($44\%$). We also demonstrate superior results on arithmetic expression and longest increasing subsequence (LIS) datasets. Our findings highlight the importance of preventing intermediate layer representation collapse to enhance the reasoning capabilities of Transformers and show that Seq-VCR offers an effective solution without requiring explicit CoT supervision.