---
title: 'FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models'
date: 2024-11-01
tags: ['token-level discrete prompt optimization', 'attention mechanism', 'natural language processing', 'large language models', 'multi-party model fine-tuning', 'federated learning', 'computational demands', 'fine-tuning', 'privacy leakage', 'semantic similarity', 'storage costs', 'DBSCAN clustering']
categories: ['cs.CL']
problem: f
solution: ['privacy leakage risks in fine-tuning large language models']
pdf_url: http://arxiv.org/pdf/2411.00985v1
arx_url: http://arxiv.org/abs/2411.00985v1
score: 5
authors: ['Jiaqi Wu', 'Simin Chen', 'Yuzhe Yang', 'Yijiang Li', 'Shiyue Hou', 'Rui Jing', 'Zehua Wang', 'Wei Chen', 'Zijian Tian']
affiliations_aligned: ['China University of Mining and Technology, Beijing', 'University of Texas at Dallas', 'The Chinese University of Hong Kong, Shenzhen', 'China University of Mining and Technology, Beijing', 'China University of Mining and Technology, Beijing', 'China University of Mining and Technology, Beijing', 'China University of Mining and Technology, Beijing', 'China University of Mining and Technology, Beijing', 'China University of Mining and Technology, Beijing']
affiliations: ['China University of Mining and Technology, Beijing', 'University of Texas at Dallas', 'The Chinese University of Hong Kong, Shenzhen']
---


In recent years, large language models (LLMs) have significantly advanced the field of natural language processing (NLP). By fine-tuning LLMs with data from specific scenarios, these foundation models can better adapt to various downstream tasks. However, the fine-tuning process poses privacy leakage risks, particularly in centralized data processing scenarios. To address user privacy concerns, federated learning (FL) has been introduced to mitigate the risks associated with centralized data collection from multiple sources. Nevertheless, the privacy of LLMs themselves is equally critical, as potential malicious attacks challenge their security, an issue that has received limited attention in current research. Consequently, establishing a trusted multi-party model fine-tuning environment is essential. Additionally, the local deployment of large LLMs incurs significant storage costs and high computational demands. To address these challenges, we propose for the first time a federated discrete and transferable prompt tuning, namely FedDTPT, for black-box large language models. In the client optimization phase, we adopt a token-level discrete prompt optimization method that leverages a feedback loop based on prediction accuracy to drive gradient-free prompt optimization through the MLM API. For server optimization, we employ an attention mechanism based on semantic similarity to filter all local prompt tokens, along with an embedding distance elbow detection and DBSCAN clustering strategy to enhance the filtering process. Experimental results demonstrate that, compared to state-of-the-art methods, our approach achieves higher accuracy, reduced communication overhead, and robustness to non-iid data in a black-box setting. Moreover, the optimized prompts are transferable.