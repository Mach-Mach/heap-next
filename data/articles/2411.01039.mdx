---
title: 'Enhancing Question Answering Precision with Optimized Vector Retrieval and Instructions'
date: 2024-11-01
tags: ['Information Retrieval', 'Pre-trained Large Neural Networks', 'Optimized Vector Retrieval', 'Question Answering', 'Language Models', 'Text Segmentation Techniques', 'Context Construction', 'Similarity Functions', 'Document Embedding']
categories: ['cs.CL', 'cs.IR', 'cs.LG']
problem: i
solution: ['intensive computational resources for fine-tuning QA performances']
pdf_url: http://arxiv.org/pdf/2411.01039v1
arx_url: http://arxiv.org/abs/2411.01039v1
score: 5
authors: ['Lixiao Yang', 'Mengyang Xu', 'Weimao Ke']
affiliations_aligned: ['Drexel University', 'Drexel University', 'Drexel University']
affiliations: ['Drexel University']
---


Question-answering (QA) is an important application of Information Retrieval (IR) and language models, and the latest trend is toward pre-trained large neural networks with embedding parameters. Augmenting QA performances with these LLMs requires intensive computational resources for fine-tuning. We propose an innovative approach to improve QA task performances by integrating optimized vector retrievals and instruction methodologies. Based on retrieval augmentation, the process involves document embedding, vector retrieval, and context construction for optimal QA results. We experiment with different combinations of text segmentation techniques and similarity functions, and analyze their impacts on QA performances. Results show that the model with a small chunk size of 100 without any overlap of the chunks achieves the best result and outperforms the models based on semantic segmentation using sentences. We discuss related QA examples and offer insight into how model performances are improved within the two-stage framework.