---
title: 'RAGViz: Diagnose and Visualize Retrieval-Augmented Generation'
date: 2024-11-04
tags: ['retrieval-augmented generation', 'HuggingFace', 'large language models', 'attention mechanisms', 'visualization', 'LLM inference', 'Approximate Nearest Neighbor', 'open-source toolkit', 'custom embedding model']
categories: ['cs.CL', 'cs.AI']
problem: R
solution: ['lack of customizable visibility on context documents and model attentiveness']
pdf_url: http://arxiv.org/pdf/2411.01751v1
arx_url: http://arxiv.org/abs/2411.01751v1
score: 5
authors: ['Tevin Wang', 'Jingyuan He', 'Chenyan Xiong']
affiliations_aligned: ['School of Computer Science, Carnegie Mellon University', 'School of Computer Science, Carnegie Mellon University', 'School of Computer Science, Carnegie Mellon University']
affiliations: ['School of Computer Science, Carnegie Mellon University']
---


Retrieval-augmented generation (RAG) combines knowledge from domain-specific sources into large language models to ground answer generation. Current RAG systems lack customizable visibility on the context documents and the model's attentiveness towards such documents. We propose RAGViz, a RAG diagnosis tool that visualizes the attentiveness of the generated tokens in retrieved documents. With a built-in user interface, retrieval index, and Large Language Model (LLM) backbone, RAGViz provides two main functionalities: (1) token and document-level attention visualization, and (2) generation comparison upon context document addition and removal. As an open-source toolkit, RAGViz can be easily hosted with a custom embedding model and HuggingFace-supported LLM backbone. Using a hybrid ANN (Approximate Nearest Neighbor) index, memory-efficient LLM inference tool, and custom context snippet method, RAGViz operates efficiently with a median query time of about 5 seconds on a moderate GPU node. Our code is available at https://github.com/cxcscmu/RAGViz. A demo video of RAGViz can be found at https://youtu.be/cTAbuTu6ur4.