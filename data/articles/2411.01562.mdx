---
title: 'Are LLMs good pragmatic speakers?'
date: 2024-11-03
tags: ['large language models', 'truth-conditional meaning function', 'referential utterances', 'human communication', 'reference game', 'natural language pragmatics', 'pragmatic reasoning', 'TUNA corpus', 'human-subject evaluation', 'Rational Speech Act framework']
categories: ['cs.CL', 'cs.AI']
problem: c
solution: ['whether LLMs behave like pragmatic speakers']
pdf_url: http://arxiv.org/pdf/2411.01562v1
arx_url: http://arxiv.org/abs/2411.01562v1
score: 5
authors: ['Mingyue Jian', 'Siddharth Narayanaswamy']
affiliations_aligned: ['University of Edinburgh', 'University of Edinburgh']
affiliations: ['University of Edinburgh']
---


Large language models (LLMs) are trained on data assumed to include natural language pragmatics, but do they actually behave like pragmatic speakers? We attempt to answer this question using the Rational Speech Act (RSA) framework, which models pragmatic reasoning in human communication. Using the paradigm of a reference game constructed from the TUNA corpus, we score candidate referential utterances in both a state-of-the-art LLM (Llama3-8B-Instruct) and in the RSA model, comparing and contrasting these scores. Given that RSA requires defining alternative utterances and a truth-conditional meaning function, we explore such comparison for different choices of each of these requirements. We find that while scores from the LLM have some positive correlation with those from RSA, there isn't sufficient evidence to claim that it behaves like a pragmatic speaker. This initial study paves way for further targeted efforts exploring different models and settings, including human-subject evaluation, to see if LLMs truly can, or be made to, behave like pragmatic speakers.