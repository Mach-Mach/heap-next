---
title: 'DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems'
date: 2024-11-01
tags: ['entity types', 'domain-specific knowledge', 'agent modeling approaches', 'MultiWOZ benchmark', 'multi-agent conversational system', 'task-oriented dialogue systems', 'dialogue inform rate', 'Large Language Models', 'fine-tuned models', 'MultiWOZ dataset', 'multi-domain systems', 'dialog manager agent', 'annotator discrepancies', 'success rate', 'user intents']
categories: ['cs.CL', 'cs.AI']
problem: DARD (Domain Assigned Response Delegation)
solution: developing effective multi-domain systems
pdf_url: http://arxiv.org/pdf/2411.00427v1
arx_url: http://arxiv.org/abs/2411.00427v1
score: 7
authors: ['Aman Gupta', 'Anirudh Ravichandran', 'Ziji Zhang', 'Swair Shah', 'Anurag Beniwal', 'Narayanan Sadagopan']
affiliations_aligned: ['Carnegie Mellon University', 'Amazon', 'Amazon', 'Amazon', 'Amazon', 'Amazon']
affiliations: ['Carnegie Mellon University', 'Amazon']
---


Task-oriented dialogue systems are essential for applications ranging from customer service to personal assistants and are widely used across various industries. However, developing effective multi-domain systems remains a significant challenge due to the complexity of handling diverse user intents, entity types, and domain-specific knowledge across several domains. In this work, we propose DARD (Domain Assigned Response Delegation), a multi-agent conversational system capable of successfully handling multi-domain dialogs. DARD leverages domain-specific agents, orchestrated by a central dialog manager agent. Our extensive experiments compare and utilize various agent modeling approaches, combining the strengths of smaller fine-tuned models (Flan-T5-large & Mistral-7B) with their larger counterparts, Large Language Models (LLMs) (Claude Sonnet 3.0). We provide insights into the strengths and limitations of each approach, highlighting the benefits of our multi-agent framework in terms of flexibility and composability. We evaluate DARD using the well-established MultiWOZ benchmark, achieving state-of-the-art performance by improving the dialogue inform rate by 6.6% and the success rate by 4.1% over the best-performing existing approaches. Additionally, we discuss various annotator discrepancies and issues within the MultiWOZ dataset and its evaluation system.