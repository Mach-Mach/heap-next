---
title: Prompt Engineering Using GPT for Word-Level Code-Mixed Language
  Identification in Low-Resource Dravidian Languages
date: 2024_11_06
tags: ['Dravidian languages', 'information retrieval', 'Language Identification', 'machine translation', 'code-mixing', 'morphological structures', 'natural language processing', 'GPT-3.5 Turbo', 'social media']
categories: ['cs.CL']
problem: prompt based method using GPT-3.5 Turbo
solution: ['word-level language identification challenges in Dravidian languages']
pdf_url: http://arxiv.org/pdf/2411.04025v1
arx_url: http://arxiv.org/abs/2411.04025v1
score: 5
authors: ['Aniket Deroy', 'Subhankar Maity']
affiliations_aligned: ['IIT Kharagpur, Kharagpur, India', 'IIT Kharagpur, Kharagpur, India']
affiliations: ['IIT Kharagpur, Kharagpur, India']
---


Language Identification (LI) is crucial for various natural language
processing tasks, serving as a foundational step in applications such as
sentiment analysis, machine translation, and information retrieval. In
multilingual societies like India, particularly among the youth engaging on
social media, text often exhibits code-mixing, blending local languages with
English at different linguistic levels. This phenomenon presents formidable
challenges for LI systems, especially when languages intermingle within single
words. Dravidian languages, prevalent in southern India, possess rich
morphological structures yet suffer from under-representation in digital
platforms, leading to the adoption of Roman or hybrid scripts for
communication. This paper introduces a prompt based method for a shared task
aimed at addressing word-level LI challenges in Dravidian languages. In this
work, we leveraged GPT-3.5 Turbo to understand whether the large language
models is able to correctly classify words into correct categories. Our
findings show that the Kannada model consistently outperformed the Tamil model
across most metrics, indicating a higher accuracy and reliability in
identifying and categorizing Kannada language instances. In contrast, the Tamil
model showed moderate performance, particularly needing improvement in
precision and recall.