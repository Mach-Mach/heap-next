---
title: 'Cascaded Dual Vision Transformer for Accurate Facial Landmark Detection'
date: 2024-11-12
tags: ['Channel-split ViT', 'WFLW', 'intermediate supervision', 'geometric relations', 'vision transformers', 'computer vision', 'Long Skip Connections', 'prediction blocks', 'performance evaluation', 'benchmarks', 'COFW', '300W', 'spatial-split ViT', 'heatmap space', 'low-level image features', 'facial landmark detection', 'Dual Vision Transformer']
categories: ['cs.CV']
problem: Cascaded Dual Vision Transformer
solution: facial landmark detection
pdf_url: https://arxiv.org/pdf/2411.07167
arx_url: https://arxiv.org/abs/2411.07167
score: 4
authors: ['Ziqiang Dang', 'Jianfang Li', 'Lin Liu']
affiliations_aligned: ['Zhejiang University', 'Institute for Intelligent Computing, Alibaba Group', 'Institute for Intelligent Computing, Alibaba Group']
affiliations: ['Zhejiang University', 'Institute for Intelligent Computing, Alibaba Group']
---


Facial landmark detection is a fundamental problem in computer vision for many downstream applications. This paper introduces a new facial landmark detector based on vision transformers, which consists of two unique designs: Dual Vision Transformer (D-ViT) and Long Skip Connections (LSC). Based on the observation that the channel dimension of feature maps essentially represents the linear bases of the heatmap space, we propose learning the interconnections between these linear bases to model the inherent geometric relations among landmarks via Channel-split ViT. We integrate such channel-split ViT into the standard vision transformer (i.e., spatial-split ViT), forming our Dual Vision Transformer to constitute the prediction blocks. We also suggest using long skip connections to deliver low-level image features to all prediction blocks, thereby preventing useful information from being discarded by intermediate supervision. Extensive experiments are conducted to evaluate the performance of our proposal on the widely used benchmarks, i.e., WFLW, COFW, and 300W, demonstrating that our model outperforms the previous SOTAs across all three benchmarks.