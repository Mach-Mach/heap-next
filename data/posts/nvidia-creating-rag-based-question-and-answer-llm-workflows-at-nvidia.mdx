---
title: 'Creating RAG-Based Question-and-Answer LLM Workflows at NVIDIA'
date: 2024-10-28
categories: ['Conversational AI', 'Generative AI', 'featured', 'Microservices', 'Retrieval Augmented Generation (RAG)']
url: https://developer.nvidia.com/blog/creating-rag-based-question-and-answer-llm-workflows-at-nvidia/
company: NVIDIA
authors: ['Chris Krapu']
summary: 'The rapid development of solutions using retrieval augmented generation (RAG) for question-and-answer LLM workflows has led to new types of system...'
---


![GIF shows chat app in use.](https://developer-blogs.nvidia.com/wp-
content/uploads/2024/10/llamaindex-workflow-chat-app-featured-1.gif)The rapid
development of solutions using retrieval augmented generation (RAG) for
question-and-answer LLM workflows has led to new types of system...![GIF shows
chat app in use.](https://developer-blogs.nvidia.com/wp-
content/uploads/2024/10/llamaindex-workflow-chat-app-featured-1.gif)

The rapid development of solutions using retrieval augmented generation (RAG)
for question-and-answer LLM workflows has led to new types of system
architectures. Our work at NVIDIA using AI for internal operations has led to
several important findings for finding alignment between system capabilities
and user expectations. We found that regardless of the intended scope or use
caseâ€¦

[Source](https://developer.nvidia.com/blog/creating-rag-based-question-and-
answer-llm-workflows-at-nvidia/)

