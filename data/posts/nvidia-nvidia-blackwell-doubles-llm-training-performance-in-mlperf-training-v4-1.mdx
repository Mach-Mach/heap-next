---
title: 'NVIDIA Blackwell Doubles LLM Training Performance in MLPerf Training v4.1'
date: 2024-11-13
categories: ['Data Center / Cloud', 'Generative AI', 'Networking / Communications', 'Top Stories', 'featured', 'Llama', 'LLMs', 'MLPerf', 'Training AI Models']
url: https://developer.nvidia.com/blog/nvidia-blackwell-doubles-llm-training-performance-in-mlperf-training-v4-1/
company: NVIDIA
authors: ['Sukru Burc Eryilmaz']
summary: 'As models grow larger and are trained on more data, they become more capable, making them more useful. To train these models quickly, more performance,...'
---


![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/NVIDIA-
Blackwell-Doubles-LLM-Training-Performance-in-MLPerf-Training-v4.1.png)As
models grow larger and are trained on more data, they become more capable,
making them more useful. To train these models quickly, more
performance,...![](https://developer-blogs.nvidia.com/wp-
content/uploads/2024/11/NVIDIA-Blackwell-Doubles-LLM-Training-Performance-in-
MLPerf-Training-v4.1.png)

As models grow larger and are trained on more data, they become more capable,
making them more useful. To train these models quickly, more performance,
delivered at data center scale, is required. The NVIDIA Blackwell platform,
launched at GTC 2024 and now in full production, integrates seven types of
chips: GPU, CPU, DPU, NVLink Switch chip, InfiniBand Switch, and Ethernet
Switch.

[Source](https://developer.nvidia.com/blog/nvidia-blackwell-doubles-llm-
training-performance-in-mlperf-training-v4-1/)

