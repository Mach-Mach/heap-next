[{"title":"Enhancing Multimodal Query Representation via Visual Dialogues for End-to-End Knowledge Retrieval","date":"2024-11-14T00:00:00.000Z","tags":["fine-tuning scenarios","end-to-end retrieval system","image comprehension","partial convolution mechanism","multimodal query representations","dynamic modality interaction","visual information","Visual Dialogue-to-Retrieval dataset","caption generators","information retrieval tasks","zero-shot settings","object detectors","multimodal retrieval systems"],"categories":["cs.IR","cs.MM","cs.AI","cs.CV"],"pdf_url":"https://arxiv.org/pdf/2411.08334","arx_url":"https://arxiv.org/abs/2411.08334","authors":["Yeong-Joon Ju","Ho-Joong Kim","Seong-Whan Lee"],"affiliations_aligned":["Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea","Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea","Department of Computer Science and Engineering, Pohang University of Science and Technology, Pohang, South Korea"],"affiliations":["Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea","Department of Computer Science and Engineering, Pohang University of Science and Technology, Pohang, South Korea"],"problem":"disjointed models for image comprehension","solution":"end-to-end retrieval system Ret-XKnow","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.705,"time":42300,"words":141},"slug":"2411.08334","path":"articles/2411.08334","filePath":"articles/2411.08334.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Enhancing Multimodal Query Representation via Visual Dialogues for End-to-End Knowledge Retrieval","datePublished":"2024-11-14T00:00:00.000Z","dateModified":"2024-11-14T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.08334"}},{"title":"CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation from LLMs","date":"2024-11-14T00:00:00.000Z","tags":["bias in data","data synthesis","student model","diversity","large language models","correlated sampling","prompt adherence","dataset generation","decoding-time guidance","intrinsic evaluation"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.08553","arx_url":"https://arxiv.org/abs/2411.08553","authors":["Suhas S Kowshik","Abhishek Divekar","Vijit Malik"],"affiliations_aligned":["Amazon","Amazon","Amazon"],"affiliations":["Amazon"],"problem":"lack of diversity in generated data","solution":"CorrSynth method for diverse dataset generation","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.865,"time":51900,"words":173},"slug":"2411.08553","path":"articles/2411.08553","filePath":"articles/2411.08553.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation from LLMs","datePublished":"2024-11-14T00:00:00.000Z","dateModified":"2024-11-14T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.08553"}},{"title":"QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain","date":"2024-11-14T00:00:00.000Z","tags":["query expansion","Retrieval-Augmented Generation","similarity scores","chunks graph","Large Language Models","evaluation datasets","transition probabilities","information retrieval techniques","tourism domain"],"categories":["cs.CL","cs.AI"],"pdf_url":"https://arxiv.org/pdf/2411.08724","arx_url":"https://arxiv.org/abs/2411.08724","authors":["Qikai Wei","Mingzhi Yang","Chunlong Han","Jingfu Wei","Minghao Zhang","Feifei Shi","Huansheng Ning"],"affiliations_aligned":["a,b","c","a,b","a,b","a,b","a,b","a,b"],"affiliations":["a,b","c"],"problem":"irrelevant or contradictory information in retrieval-augmented generation","solution":"QCG-Rerank model","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.815,"time":48900,"words":163},"slug":"2411.08724","path":"articles/2411.08724","filePath":"articles/2411.08724.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain","datePublished":"2024-11-14T00:00:00.000Z","dateModified":"2024-11-14T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.08724"}},{"title":"Multi-Document Financial Question Answering using LLMs","date":"2024-11-13T00:00:00.000Z","tags":["knowledge graph","semantic tagging","knowledge distillation","LLM based scoring","multi-document financial question answering","RAG methods","evaluation metrics"],"categories":["cs.IR","cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.07264","arx_url":"https://arxiv.org/abs/2411.07264","authors":["Shalin Shah","Srikanth Ryali","Ramasubbu Venkatesh"],"affiliations_aligned":["Anvai AI","",""],"affiliations":["","Anvai AI"],"problem":"multi-document financial question answering","solution":"methods using semantic tagging and knowledge graphs","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.87,"time":52200,"words":174},"slug":"2411.07264","path":"articles/2411.07264","filePath":"articles/2411.07264.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Multi-Document Financial Question Answering using LLMs","datePublished":"2024-11-13T00:00:00.000Z","dateModified":"2024-11-13T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.07264"}},{"title":"SetLexSem Challenge: Using Set Operations to Evaluate the Lexical and Semantic Robustness of Language Models","date":"2024-11-13T00:00:00.000Z","tags":["lexical variations","NLP tasks","semantic variations","algorithmic tasks","instruction-following abilities","set operations","set theory","robustness evaluation","synthetic benchmark","language models"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.07336","arx_url":"https://arxiv.org/abs/2411.07336","authors":["Bardiya Akhbari","Manish Gawali","Nicholas A. Dronen"],"affiliations_aligned":["Amazon","Amazon","Amazon"],"affiliations":["Amazon"],"problem":"poor robustness of language models to variation in set operations and operands","solution":"SetLexSem Challenge benchmark for evaluating language model performance","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.135,"time":68100,"words":227},"slug":"2411.07336","path":"articles/2411.07336","filePath":"articles/2411.07336.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"SetLexSem Challenge: Using Set Operations to Evaluate the Lexical and Semantic Robustness of Language Models","datePublished":"2024-11-13T00:00:00.000Z","dateModified":"2024-11-13T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.07336"}},{"title":"IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark","date":"2024-11-13T00:00:00.000Z","tags":["coreference resolution","LLMs","model performance","pronominal mentions","nominal mentions","multiple-choice question format","nested structures","long narratives","mention resolution","evaluation metrics"],"categories":["cs.LG","cs.AI","cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.07466","arx_url":"https://arxiv.org/abs/2411.07466","authors":["Kawshik Manikantan","Makarand Tapaswi","Vineet Gandhi","Shubham Toshniwal"],"affiliations_aligned":["CVIT, IIIT Hyderabad","CVIT, IIIT Hyderabad","CVIT, IIIT Hyderabad","NVIDIA"],"affiliations":["CVIT, IIIT Hyderabad","NVIDIA"],"problem":"limitations of traditional output formats and evaluation metrics in capturing referential understanding","solution":"IdentifyMe benchmark for mention resolution","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.86,"time":51600,"words":172},"slug":"2411.07466","path":"articles/2411.07466","filePath":"articles/2411.07466.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark","datePublished":"2024-11-13T00:00:00.000Z","dateModified":"2024-11-13T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.07466"}},{"title":"SparrowVQE: Visual Question Explanation for Course Content Understanding","date":"2024-11-13T00:00:00.000Z","tags":["benchmark VQA datasets","Visual Question Answering","Phi-2 language model","feature alignment","domain fine-tuning","multimodal model","machine learning course","MLVQE dataset","SigLIP model","instruction tuning","training mechanism","Visual Question Explanation","MLP adapter"],"categories":["cs.CL","cs.CV"],"pdf_url":"https://arxiv.org/pdf/2411.07516","arx_url":"https://arxiv.org/abs/2411.07516","authors":["Jialu Li","Manish Kumar Thota","Ruslan Gokhman","Radek Holik","Youshan Zhang"],"affiliations_aligned":["Artificial Intelligence, Graduate Computer Science and Engineering Department, Yeshiva University, NY, USA","Artificial Intelligence, Graduate Computer Science and Engineering Department, Yeshiva University, NY, USA","Artificial Intelligence, Graduate Computer Science and Engineering Department, Yeshiva University, NY, USA","Artificial Intelligence, Graduate Computer Science and Engineering Department, Yeshiva University, NY, USA","Artificial Intelligence, Graduate Computer Science and Engineering Department, Yeshiva University, NY, USA"],"affiliations":["Artificial Intelligence, Graduate Computer Science and Engineering Department, Yeshiva University, NY, USA"],"problem":"overly simplistic and short answers in VQA methods","solution":"SparrowVQE multimodal model","score":8,"type":"Blog","readingTime":{"text":"1 min read","minutes":1.005,"time":60300,"words":201},"slug":"2411.07516","path":"articles/2411.07516","filePath":"articles/2411.07516.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"SparrowVQE: Visual Question Explanation for Course Content Understanding","datePublished":"2024-11-13T00:00:00.000Z","dateModified":"2024-11-13T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.07516"}},{"title":"Autoregressive Models in Vision: A Survey","date":"2024-11-12T00:00:00.000Z","tags":["3D generation","multi-modal generation","embodied AI","video generation","autoregessive modeling","sequence representation","3D medical AI","token-based models","generative models","natural language processing","image generation","visual content generation","research challenges","pixel-based models","computer vision","scale-based models"],"categories":["cs.CL","cs.CV"],"pdf_url":"https://arxiv.org/pdf/2411.05902","arx_url":"https://arxiv.org/abs/2411.05902","authors":["Jing Xiong","Gongye Liu","Lun Huang","Chengyue Wu","Taiqiang Wu","Yao Mu","Yuan Yao","Hui Shen","Zhongwei Wan","Jinfa Huang","Chaofan Tao","Shen Yan","Huaxiu Yao","Lingpeng Kong","Hongxia Yang","Mi Zhang","Guillermo Sapiro","Jiebo Luo","Ping Luo","Ngai Wong"],"affiliations_aligned":["The University of Hong Kong","Tsinghua University","Duke University","The University of Hong Kong","The University of Hong Kong","The University of Hong Kong","University of Rochester","The Ohio State University","The Ohio State University","University of Rochester","The University of Hong Kong","Bytedance","The University of North Carolina at Chapel Hill","The University of Hong Kong","The Hong Kong Polytechnic University","The Ohio State University","Apple","University of Rochester","The University of Hong Kong","The University of Hong Kong"],"affiliations":["Tsinghua University","The University of Hong Kong","University of Rochester","The Hong Kong Polytechnic University","Apple","Duke University","Bytedance","The University of North Carolina at Chapel Hill","The Ohio State University"],"problem":"current challenges to autoregressive models in vision","solution":"multi-faceted categorization of autoregressive models in computer vision","score":7,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.145,"time":68700,"words":229},"slug":"2411.05902","path":"articles/2411.05902","filePath":"articles/2411.05902.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Autoregressive Models in Vision: A Survey","datePublished":"2024-11-12T00:00:00.000Z","dateModified":"2024-11-12T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.05902"}},{"title":"GUIDEQ: Framework for Guided Questioning for progressive informational collection and classification","date":"2024-11-12T00:00:00.000Z","tags":["classification accuracy","Question Answering","customer support","explainability","guided questions","classifier model","information gathering","text classification","legal services","F1-Score","prompting strategy","healthcare","LLMs"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.05991","arx_url":"https://arxiv.org/abs/2411.05991","authors":["Priya Mishra","Suraj Racha","Kaustubh Ponkshe","Adit Akarsh","Ganesh Ramakrishnan"],"affiliations_aligned":["Indian Institute of Technology Bombay","Indian Institute of Technology Bombay","Indian Institute of Technology Bombay","Indian Institute of Technology Bombay","Indian Institute of Technology Bombay"],"affiliations":["Indian Institute of Technology Bombay"],"problem":"insufficient or missing information for classification","solution":"GUIDEQ framework for guided questioning","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.06,"time":63600,"words":212},"slug":"2411.05991","path":"articles/2411.05991","filePath":"articles/2411.05991.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"GUIDEQ: Framework for Guided Questioning for progressive informational collection and classification","datePublished":"2024-11-12T00:00:00.000Z","dateModified":"2024-11-12T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.05991"}},{"title":"M-Longdoc: A Benchmark For Multimodal Super-Long Document Understanding And A Retrieval-Aware Tuning Framework","date":"2024-11-12T00:00:00.000Z","tags":["question-answering","large multimodal models","multimodal document understanding","retrieval-aware tuning","automated methods","benchmarking"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.06176","arx_url":"https://arxiv.org/abs/2411.06176","authors":["Yew Ken Chia","Liying Cheng","Hou Pong Chan","Chaoqun Liu","Maojia Song","Sharifah Mahani Aljunied","Soujanya Poria","Lidong Bing"],"affiliations_aligned":["Singapore University of Technology and Design","DAMO Academy, Alibaba Group, Singapore","Nanyang Technological University, Singapore","DAMO Academy, Alibaba Group, Singapore","Singapore University of Technology and Design","DAMO Academy, Alibaba Group, Singapore","Singapore University of Technology and Design","DAMO Academy, Alibaba Group, Singapore"],"affiliations":["Nanyang Technological University, Singapore","DAMO Academy, Alibaba Group, Singapore","Singapore University of Technology and Design"],"problem":"understanding and answering questions over lengthy multimodal documents","solution":"M-LongDoc benchmark and retrieval-aware tuning framework","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.99,"time":59400,"words":198},"slug":"2411.06176","path":"articles/2411.06176","filePath":"articles/2411.06176.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"M-Longdoc: A Benchmark For Multimodal Super-Long Document Understanding And A Retrieval-Aware Tuning Framework","datePublished":"2024-11-12T00:00:00.000Z","dateModified":"2024-11-12T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.06176"}},{"title":"Exploring Knowledge Boundaries in Large Language Models for Retrieval Judgment","date":"2024-11-12T00:00:00.000Z","tags":["dynamic knowledge","multi-hop problems","Large Language Models","performance improvement","Retrieval-Augmented Generation","Knowledge Boundary Model","knowledge boundary","question answering capabilities","long-tail static knowledge","computational costs"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.06207","arx_url":"https://arxiv.org/abs/2411.06207","authors":["Zhen Zhang","Xinyu Wang","Yong Jiang","Zhuo Chen","Feiteng Mu","Mengting Hu","Pengjun Xie","Fei Huang"],"affiliations_aligned":["Alibaba Group","Alibaba Group","Alibaba Group","Alibaba Group","Alibaba Group","Alibaba Group","Alibaba Group","Alibaba Group"],"affiliations":["Alibaba Group"],"problem":"challenges in dynamically changing knowledge and managing unknown static knowledge","solution":"Knowledge Boundary Model","score":8,"type":"Blog","readingTime":{"text":"1 min read","minutes":1.005,"time":60300,"words":201},"slug":"2411.06207","path":"articles/2411.06207","filePath":"articles/2411.06207.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Exploring Knowledge Boundaries in Large Language Models for Retrieval Judgment","datePublished":"2024-11-12T00:00:00.000Z","dateModified":"2024-11-12T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.06207"}},{"title":"Explore the Reasoning Capability of LLMs in the Chess Testbed","date":"2024-11-12T00:00:00.000Z","tags":["long-term strategic play","large language models","short-term tactical play","finetuning LLaMA-3-8B","annotated strategy and tactic","chess","comparison with commercial language models","language explanations","dataset MATE","reasoning capability"],"categories":["cs.AI","cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.06655","arx_url":"https://arxiv.org/abs/2411.06655","authors":["Shu Wang","Lei Ji","Renxi Wang","Wenxiao Zhao","Haokun Liu","Yifan Hou","Ying Nian Wu"],"affiliations_aligned":["UCLA","Microsoft Research","MBZUAI","UCLA","University of Toronto","Peking University","UCLA"],"affiliations":["Microsoft Research","UCLA","University of Toronto","Peking University","MBZUAI"],"problem":"long-term complex reasoning tasks in chess","solution":"integration of annotated strategy and tactic in large language models","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.79,"time":47400,"words":158},"slug":"2411.06655","path":"articles/2411.06655","filePath":"articles/2411.06655.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Explore the Reasoning Capability of LLMs in the Chess Testbed","datePublished":"2024-11-12T00:00:00.000Z","dateModified":"2024-11-12T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.06655"}},{"title":"Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text Embeddings Must Adapt","date":"2024-11-12T00:00:00.000Z","tags":["text embeddings","question answering","finance","benchmarks","domain-specific training","public datasets","dataset scale","hard negative mining"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.07142","arx_url":"https://arxiv.org/abs/2411.07142","authors":["Peter Anderson","Mano Vikash Janardhanan","Jason He","Wei Cheng","Charlie Flanagan"],"affiliations_aligned":["Balyasny Asset Management","Balyasny Asset Management","Balyasny Asset Management","Balyasny Asset Management","Balyasny Asset Management"],"affiliations":["Balyasny Asset Management"],"problem":"challenges for general-purpose text embeddings in finance","solution":"BAM embeddings finetuned on a dataset of query-passage pairs","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.705,"time":42300,"words":141},"slug":"2411.07142","path":"articles/2411.07142","filePath":"articles/2411.07142.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text Embeddings Must Adapt","datePublished":"2024-11-12T00:00:00.000Z","dateModified":"2024-11-12T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.07142"}},{"title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding for Fast Listwise Reranking","date":"2024-11-11T00:00:00.000Z","tags":["backbone models","learning-to-rank objective","zero-shot single-token reranking","listwise reranking","large language models","computational demands","inference latency","TREC Deep Learning datasets","LM pre-training","first-stage retrievers"],"categories":["cs.IR","cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.05508","arx_url":"https://arxiv.org/abs/2411.05508","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"affiliations_aligned":["David R. Cheriton School of Computer Science, University of Waterloo","David R. Cheriton School of Computer Science, University of Waterloo","David R. Cheriton School of Computer Science, University of Waterloo"],"affiliations":["David R. Cheriton School of Computer Science, University of Waterloo"],"problem":"high computational demands of large language models for listwise reranking","solution":"FIRST approach integrating learning-to-rank objective and single-token logits","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.075,"time":64500,"words":215},"slug":"2411.05508","path":"articles/2411.05508","filePath":"articles/2411.05508.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"An Early FIRST Reproduction and Improvements to Single-Token Decoding for Fast Listwise Reranking","datePublished":"2024-11-11T00:00:00.000Z","dateModified":"2024-11-11T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.05508"}},{"title":"ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles","date":"2024-11-11T00:00:00.000Z","tags":["technical concepts","interpreters","parallel corpus","signed languages","fingerspelling","ASL STEM Wiki","Deaf and hard-of-hearing students","AI resources","STEM education"],"categories":["cs.HC","cs.CV","cs.CL","cs.AI"],"pdf_url":"https://arxiv.org/pdf/2411.05783","arx_url":"https://arxiv.org/abs/2411.05783","authors":["Kayo Yin","Chinmay Singh","Fyodor O. Minakov","Vanessa Milan","Hal Daum\\'e III","Cyril Zhang","Alex X. Lu","Danielle Bragg","Hal Daumé III"],"affiliations_aligned":["University of California, Berkeley","Microsoft Research","Microsoft Research","Microsoft Research","","Microsoft Research","Microsoft Research","Microsoft Research","University of Maryland"],"affiliations":["","Microsoft Research","University of California, Berkeley","University of Maryland"],"problem":"barriers in accessing STEM education for DHH students","solution":"ASL STEM Wiki dataset and models for identifying fingerspelled words","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.69,"time":41400,"words":138},"slug":"2411.05783","path":"articles/2411.05783","filePath":"articles/2411.05783.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles","datePublished":"2024-11-11T00:00:00.000Z","dateModified":"2024-11-11T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.05783"}},{"title":"GRSQA -- Graph Reasoning-Structured Question Answering Dataset","date":"2024-11-08T00:00:00.000Z","tags":["reasoning graphs","Large Language Models","multi-hop question-answering","evaluation of LLM reasoning capabilities","reasoning structures","reasoning pathways","QA datasets","semantic contexts","Graph Reasoning-Structured Question Answering Dataset","reasoning abilities"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.00369","arx_url":"https://arxiv.org/abs/2411.00369","authors":["Anish Pahilajani","Devasha Trivedi","Jincen Shuai","Khin S. Yone","Samyak Rajesh Jain","Namyong Park","Ryan A. Rossi","Nesreen K. Ahmed","Franck Dernoncourt","Yu Wang"],"affiliations_aligned":["University of California Santa Cruz","University of California Santa Cruz","University of California Santa Cruz","University of California Santa Cruz","University of California Santa Cruz","","Adobe Research","Cisco Outshift","Adobe Research","University of Oregon"],"affiliations":["","Adobe Research","University of Oregon","University of California Santa Cruz","Cisco Outshift"],"problem":"impact of reasoning structures on LLM M-QA performance","solution":"Graph Reasoning-Structured Question Answering Dataset","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.715,"time":42900,"words":143},"slug":"2411.00369","path":"articles/2411.00369","filePath":"articles/2411.00369.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"GRSQA -- Graph Reasoning-Structured Question Answering Dataset","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.00369"}},{"title":"Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula","date":"2024-11-08T00:00:00.000Z","tags":["causal generation","retrieval-intensive tasks","linear attention variants","question answering","text copying","specialized pre-training objectives","bidirectional input processing","linear recurrent neural networks","architectural modifications","computational efficiency","training procedure","bidirectional SSM architecture","Transformers","in-context retrieval","associative recall","reinforcement learning","long paragraph question-answering","infilling","multi-number phone book lookup","state space models"],"categories":["cs.AI","cs.CL","cs.LG"],"pdf_url":"https://arxiv.org/pdf/2411.01030","arx_url":"https://arxiv.org/abs/2411.01030","authors":["Sam Blouir","Jimmy T. H. Smith","Antonios Anastasopoulos","Amarda Shehu","Jimmy T.H. Smith"],"affiliations_aligned":["Department of Computer Science, George Mason University, Fairfax, VA","","Department of Computer Science, George Mason University, Fairfax, VA; Archimedes AI, Athena RC, Athens, Greece","Department of Computer Science, George Mason University, Fairfax, VA","Stanford University, Stanford, CA"],"affiliations":["","Department of Computer Science, George Mason University, Fairfax, VA; Archimedes AI, Athena RC, Athens, Greece","Stanford University, Stanford, CA","Department of Computer Science, George Mason University, Fairfax, VA"],"problem":"long-range in-context retrieval challenges in state space models","solution":"novel training procedure Birdie for enhancing in-context retrieval capabilities","score":7,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.905,"time":54300,"words":181},"slug":"2411.01030","path":"articles/2411.01030","filePath":"articles/2411.01030.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.01030"}},{"title":"Typicalness-Aware Learning for Failure Detection","date":"2024-11-08T00:00:00.000Z","tags":["cross-entropy loss","atypical samples","logit direction","Area Under the Risk-Coverage Curve","failure detection","metric for typicalness","logit magnitude","benchmark datasets","Typicalness-Aware Learning","Deep neural networks","overconfidence issue"],"categories":["cs.CV"],"pdf_url":"https://arxiv.org/pdf/2411.01981","arx_url":"https://arxiv.org/abs/2411.01981","authors":["Yijun Liu","Jiequan Cui","Zhuotao Tian","Senqiao Yang","Qingdong He","Xiaoling Wang","Jingyong Su"],"affiliations_aligned":["Harbin Institute of Technology (Shenzhen)","Nanyang Technological University","Harbin Institute of Technology (Shenzhen)","The Chinese University of Hong Kong","Tencent Youtu Lab","Harbin Institute of Technology (Shenzhen)","Harbin Institute of Technology (Shenzhen)"],"affiliations":["Harbin Institute of Technology (Shenzhen)","Tencent Youtu Lab","Nanyang Technological University","The Chinese University of Hong Kong"],"problem":"overconfidence issue in deep neural networks","solution":"Typicalness-Aware Learning approach","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":1,"time":60000,"words":200},"slug":"2411.01981","path":"articles/2411.01981","filePath":"articles/2411.01981.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Typicalness-Aware Learning for Failure Detection","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.01981"}},{"title":"AmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset","date":"2024-11-08T00:00:00.000Z","tags":["search engines","finetuning","Query Autocomplete","user-typed prefixes","Prefix Trees","semantic retrieval","Large Language Models","user needs","context-dependent modeling","AmazonQAC dataset","large-scale datasets"],"categories":["cs.AI","cs.IR","cs.LG"],"pdf_url":"https://arxiv.org/pdf/2411.04129","arx_url":"https://arxiv.org/abs/2411.04129","authors":["Dante Everaert","Rohit Patki","Tianqi Zheng","Christopher Potts"],"affiliations_aligned":["Amazon Search","Amazon Search","Amazon Search","Stanford University"],"affiliations":["Amazon Search","Stanford University"],"problem":"absence of large-scale realistic datasets for QAC","solution":"introduction of AmazonQAC dataset","score":5,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.875,"time":52500,"words":175},"slug":"2411.04129","path":"articles/2411.04129","filePath":"articles/2411.04129.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"AmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04129"}},{"title":"Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding","date":"2024-11-08T00:00:00.000Z","tags":["Chain-of-Thought","variational approaches","prompt-based methods","complex reasoning tasks","zero-shot accuracy","LaTent Reasoning Optimization","large language models","latent reasoning capabilities"],"categories":["cs.AI","cs.CL","stat.ML","cs.LG"],"pdf_url":"https://arxiv.org/pdf/2411.04282","arx_url":"https://arxiv.org/abs/2411.04282","authors":["Haolin Chen","Yihao Feng","Zuxin Liu","Weiran Yao","Akshara Prabhakar","Shelby Heinecke","Ricky Ho","Phil Mui","Silvio Savarese","Caiming Xiong","Huan Wang"],"affiliations_aligned":["Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research"],"affiliations":["Salesforce AI Research"],"problem":"complex reasoning tasks requiring multiple steps","solution":"LaTent Reasoning Optimization framework","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.78,"time":46800,"words":156},"slug":"2411.04282","path":"articles/2411.04282","filePath":"articles/2411.04282.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04282"}},{"title":"CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models","date":"2024-11-08T00:00:00.000Z","tags":["search space exploration","multi-stage planning","code generation","execution-based feedback","tree structure","large language models","benchmarks","agent-guided approaches","performance evaluation","decision-making"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.04329","arx_url":"https://arxiv.org/abs/2411.04329","authors":["Jierui Li","Hung Le","Yinbo Zhou","Caiming Xiong","Silvio Savarese","Doyen Sahoo"],"affiliations_aligned":["The University of Texas at Austin","Salesforce Research","Salesforce Research","Salesforce Research","Salesforce Research","Salesforce Research"],"affiliations":["The University of Texas at Austin","Salesforce Research"],"problem":"challenges in multi-stage planning and debugging in code generation","solution":"CodeTree framework for efficient search space exploration","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.935,"time":56100,"words":187},"slug":"2411.04329","path":"articles/2411.04329","filePath":"articles/2411.04329.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04329"}},{"title":"Measuring short-form factuality in large language models","date":"2024-11-08T00:00:00.000Z","tags":["fact-seeking questions","language models","evaluation","adversarial collection","benchmark","grading responses","model behavior"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.04368","arx_url":"https://arxiv.org/abs/2411.04368","authors":["Jason Wei","Nguyen Karina","Hyung Won Chung","Yunxin Joy Jiao","Spencer Papay","Amelia Glaese","John Schulman","William Fedus"],"affiliations_aligned":["OpenAI","OpenAI","OpenAI","OpenAI","OpenAI","OpenAI","OpenAI","OpenAI"],"affiliations":["OpenAI"],"problem":"evaluating the ability of language models to answer short, fact-seeking questions","solution":"SimpleQA benchmark","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.675,"time":40500,"words":135},"slug":"2411.04368","path":"articles/2411.04368","filePath":"articles/2411.04368.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Measuring short-form factuality in large language models","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04368"}},{"title":"ML-Promise: A Multilingual Dataset for Corporate Promise Verification","date":"2024-11-08T00:00:00.000Z","tags":["Environmental Social Governance (ESG)","greenwashing","multilingual dataset","accountability of public commitments","retrieval-augmented generation (RAG)","corporate promises","Promise Verification"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.04473","arx_url":"https://arxiv.org/abs/2411.04473","authors":["Yohei Seki","Hakusen Shu","Ana\\\\\"is Lhuissier","Hanwool Lee","Juyeon Kang","Min-Yuh Day","Chung-Chi Chen","Anaïs Lhuissier"],"affiliations_aligned":["Institute of Library, Information, and Media Science, University of Tsukuba, Japan","College of Knowledge and Library Sciences, School of Informatics, University of Tsukuba, Japan","","Shinhan Securities Co., Korea","3DS Outscale, France","Graduate Institute of Information Management, National Taipei University, Taiwan","AIST, Japan","3DS Outscale, France"],"affiliations":["","AIST, Japan","Shinhan Securities Co., Korea","3DS Outscale, France","College of Knowledge and Library Sciences, School of Informatics, University of Tsukuba, Japan","Graduate Institute of Information Management, National Taipei University, Taiwan","Institute of Library, Information, and Media Science, University of Tsukuba, Japan"],"problem":"difficulty in verifying fulfillment of promises","solution":"multilingual dataset for promise verification","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.795,"time":47700,"words":159},"slug":"2411.04473","path":"articles/2411.04473","filePath":"articles/2411.04473.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"ML-Promise: A Multilingual Dataset for Corporate Promise Verification","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04473"}},{"title":"BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages","date":"2024-11-08T00:00:00.000Z","tags":["web mining","Automatic Speech Translation","low-resource languages","AST systems","performance evaluation","data generation","Indian languages","spontaneous speech","colloquial language","BhasaAnuvaad dataset"],"categories":["cs.CL"],"pdf_url":"https://arxiv.org/pdf/2411.04699","arx_url":"https://arxiv.org/abs/2411.04699","authors":["Sparsh Jain","Ashwin Sankar","Devilal Choudhary","Dhairya Suman","Nikhil Narasimhan","Mohammed Safi Ur Rahman Khan","Anoop Kunchukuttan","Mitesh M Khapra","Raj Dabre"],"affiliations_aligned":["Nilekani Centre at AI4Bharat","Nilekani Centre at AI4Bharat","Delhi Technological University","Indian Institute of Technology, Delhi","Nilekani Centre at AI4Bharat","Nilekani Centre at AI4Bharat","Microsoft","Indian Institute of Technology, Madras","Indian Institute of Technology, Madras"],"affiliations":["Nilekani Centre at AI4Bharat","Delhi Technological University","Indian Institute of Technology, Madras","Microsoft","Indian Institute of Technology, Delhi"],"problem":"scarcity of Automatic Speech Translation datasets for Indian languages","solution":"BhasaAnuvaad dataset for speech translation involving 14 Indian languages","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.025,"time":61500,"words":205},"slug":"2411.04699","path":"articles/2411.04699","filePath":"articles/2411.04699.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04699"}},{"title":"An Effective Pipeline for Whole-Slide Image Glomerulus Segmentation","date":"2024-11-08T00:00:00.000Z","tags":["whole-slide images","state-of-the-art methods","detection coverage","kidney diseases","datasets","segmentation models","glomerulus segmentation"],"categories":["cs.CV","eess.IV"],"pdf_url":"https://arxiv.org/pdf/2411.04782","arx_url":"https://arxiv.org/abs/2411.04782","authors":["Quan Huu Cap"],"affiliations_aligned":[""],"affiliations":[""],"problem":"glomerulus segmentation in whole-slide images","solution":"practical pipeline for glomerulus segmentation","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.555,"time":33300,"words":111},"slug":"2411.04782","path":"articles/2411.04782","filePath":"articles/2411.04782.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"An Effective Pipeline for Whole-Slide Image Glomerulus Segmentation","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04782"}},{"title":"M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding","date":"2024-11-08T00:00:00.000Z","tags":["benchmark evaluation","optical character recognition","open-domain DocVQA","multi-modal RAG framework","indexing","retrieval models","Document visual question answering","multi-modal language models","text-based retrieval-augmented generation"],"categories":["cs.AI","cs.CL","cs.CV"],"pdf_url":"https://arxiv.org/pdf/2411.04952","arx_url":"https://arxiv.org/abs/2411.04952","authors":["Jaemin Cho","Debanjan Mahata","Ozan Irsoy","Yujie He","Mohit Bansal","Ozan İrsoy"],"affiliations_aligned":["UNC Chapel Hill","Bloomberg","","Bloomberg","UNC Chapel Hill","Bloomberg"],"affiliations":["","UNC Chapel Hill","Bloomberg"],"problem":"difficulties in applying existing methods in real-world scenarios","solution":"M3DocRAG multi-modal RAG framework","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.215,"time":72900,"words":243},"slug":"2411.04952","path":"articles/2411.04952","filePath":"articles/2411.04952.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04952"}},{"title":"LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation","date":"2024-11-08T00:00:00.000Z","tags":["multimodal foundational models","output embeddings","textual understanding","image captions","visual encoder","CLIP","LLMs","contrastive learning","large language models","cross-modal tasks","cross-modal representation learning"],"categories":["cs.CL","cs.CV"],"pdf_url":"https://arxiv.org/pdf/2411.04997","arx_url":"https://arxiv.org/abs/2411.04997","authors":["Weiquan Huang","Aoqi Wu","Yifan Yang","Xufang Luo","Yuqing Yang","Liang Hu","Qi Dai","Xiyang Dai","Dongdong Chen","Chong Luo","Lili Qiu"],"affiliations_aligned":["Tongji University","Tongji University","Microsoft Corporation","Microsoft Corporation","Microsoft Corporation","Tongji University","Microsoft Corporation","Microsoft Corporation","Microsoft Corporation","Microsoft Corporation","Microsoft Corporation"],"affiliations":["Tongji University","Microsoft Corporation"],"problem":"limitations of vanilla CLIP in processing long and complex texts","solution":"LLM2CLIP approach leveraging LLMs for improved multimodal representation learning","score":7,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.255,"time":75300,"words":251},"slug":"2411.04997","path":"articles/2411.04997","filePath":"articles/2411.04997.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation","datePublished":"2024-11-08T00:00:00.000Z","dateModified":"2024-11-08T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.04997"}},{"title":"PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation","date":"2024-11-07T00:00:00.000Z","tags":["grounded radiology report generation","CXR images","model training","chest X-ray dataset","bi-lingual dataset","radiology report generation","clinical imaging","annotation","dataset curation","localization"],"categories":["cs.CL","cs.CV","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.05085v1","arx_url":"http://arxiv.org/abs/2411.05085v1","authors":["Daniel C. Castro","Aurelia Bustos","Shruthi Bannur","Stephanie L. Hyland","Kenza Bouzid","Maria Teodora Wetscherek","Maria Dolores Sánchez-Valverde","Lara Jaques-Pérez","Lourdes Pérez-Rodríguez","Kenji Takeda","José María Salinas","Javier Alvarez-Valle","Joaquín Galant Herrero","Antonio Pertusa","Maria Dolores Sánchez Valverde","Lara Jaques Pérez","Lourdes Pérez Rodríguez"],"affiliations_aligned":["Microsoft Research, Cambridge, UK","","","","","","","","","","","","","","Department of Radiology, University Hospital Sant Joan d’Alacant, Spain","Department of Radiology, University Hospital Sant Joan d’Alacant, Spain","Department of Radiology, University Hospital Sant Joan d’Alacant, Spain"],"affiliations":["","Microsoft Research, Cambridge, UK","Department of Radiology, University Hospital Sant Joan d’Alacant, Spain"],"problem":"lack of manually annotated chest X-ray datasets for training GRRG models","solution":"PadChest-GR dataset for training GRRG models","score":7,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.01,"time":60600,"words":202},"slug":"2411.05085","path":"articles/2411.05085","filePath":"articles/2411.05085.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation","datePublished":"2024-11-07T00:00:00.000Z","dateModified":"2024-11-07T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.05085"}},{"title":"ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language","date":"2024-11-07T00:00:00.000Z","tags":["implicitness","text understanding","natural language processing","large language models","pairwise contrastive learning","implicit language","pragmatic interpretation","semantic meaning","scalar metric","hate speech detection","comprehension capabilities"],"categories":["cs.CL"],"pdf_url":"http://arxiv.org/pdf/2411.05172v1","arx_url":"http://arxiv.org/abs/2411.05172v1","authors":["Yuxin Wang","Xiaomeng Zhu","Weimin Lyu","Saeed Hassanpour","Soroush Vosoughi"],"affiliations_aligned":["Department of Computer Science, Dartmouth College","Department of Linguistics, Yale University","Department of Computer Science, Stony Brook University","Department of Computer Science, Dartmouth College","Department of Computer Science, Dartmouth College"],"affiliations":["Department of Linguistics, Yale University","Department of Computer Science, Dartmouth College","Department of Computer Science, Stony Brook University"],"problem":"absence of a robust metric for accurately measuring the implicitness of language","solution":"ImpScore, a novel reference-free metric formulated through an interpretable regression model","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.95,"time":57000,"words":190},"slug":"2411.05172","path":"articles/2411.05172","filePath":"articles/2411.05172.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language","datePublished":"2024-11-07T00:00:00.000Z","dateModified":"2024-11-07T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.05172"}},{"title":"QUILL: Quotation Generation Enhancement of Large Language Models","date":"2024-11-06T00:00:00.000Z","tags":["bilingual knowledge base","human preferences","Large language models","reranking metric","automatic metrics","evaluation system","quotation generation"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.03675v1","arx_url":"http://arxiv.org/abs/2411.03675v1","authors":["Jin Xiao","Bowei Zhang","Qianyu He","Jiaqing Liang","Feng Wei","Jinglei Chen","Zujie Liang","Deqing Yang","Yanghua Xiao"],"affiliations_aligned":["School of Data Science, Fudan University","School of Data Science, Fudan University","Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University","School of Data Science, Fudan University","MYbank, Ant Group","MYbank, Ant Group","MYbank, Ant Group","School of Data Science, Fudan University","Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"],"affiliations":["School of Data Science, Fudan University","MYbank, Ant Group","Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"],"problem":"struggles with quotation generation","solution":"quotation knowledge base and reranking metric","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.81,"time":48600,"words":162},"slug":"2411.03675","path":"articles/2411.03675","filePath":"articles/2411.03675.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"QUILL: Quotation Generation Enhancement of Large Language Models","datePublished":"2024-11-06T00:00:00.000Z","dateModified":"2024-11-06T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.03675"}},{"title":"3DGS-CD: 3D Gaussian Splatting-based Change Detection for Physical Object Rearrangement","date":"2024-11-06T00:00:00.000Z","tags":["change detection","object reconstruction","3DGS model update","robot workspace reset","3D scenes","physical object rearrangement","3D Gaussian Splatting","zero-shot segmentation","real-world datasets","3D changes","cluttered environments","2D object-level changes"],"categories":["cs.CV","cs.RO"],"pdf_url":"http://arxiv.org/pdf/2411.03706v1","arx_url":"http://arxiv.org/abs/2411.03706v1","authors":["Ziqi Lu","Jianbo Ye","John Leonard"],"affiliations_aligned":["Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA","Amazon, New York, NY 10018, USA","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA"],"affiliations":["Amazon, New York, NY 10018, USA","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA"],"problem":"detecting physical object rearrangements in 3D scenes","solution":"3DGS-based method for detecting changes using unaligned images","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.905,"time":54300,"words":181},"slug":"2411.03706","path":"articles/2411.03706","filePath":"articles/2411.03706.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"3DGS-CD: 3D Gaussian Splatting-based Change Detection for Physical Object Rearrangement","datePublished":"2024-11-06T00:00:00.000Z","dateModified":"2024-11-06T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.03706"}},{"title":"RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation","date":"2024-11-05T00:00:00.000Z","tags":["task language","hierarchical model","manipulation tasks","intermediate policy representations","affordance images","affordances","robot manipulation","supervision sources","knowledge transfer"],"categories":["cs.CL","cs.RO","cs.CV","cs.AI","cs.LG"],"pdf_url":"http://arxiv.org/pdf/2411.02704v1","arx_url":"http://arxiv.org/abs/2411.02704v1","authors":["Soroush Nasiriany","Sean Kirmani","Tianli Ding","Laura Smith","Yuke Zhu","Danny Driess","Dorsa Sadigh","Ted Xiao"],"affiliations_aligned":["Google DeepMind, The University of Austin at Texas","Google DeepMind, The University of Austin at Texas","Google DeepMind, The University of Austin at Texas","Google DeepMind, The University of Austin at Texas","The University of Austin at Texas","Google DeepMind, The University of Austin at Texas","Google DeepMind, The University of Austin at Texas","Google DeepMind, The University of Austin at Texas"],"affiliations":["Google DeepMind, The University of Austin at Texas","The University of Austin at Texas"],"problem":"insufficient context in existing representations for manipulation tasks","solution":"RT-Affordance model conditioning policies on affordances","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.985,"time":59100,"words":197},"slug":"2411.02704","path":"articles/2411.02704","filePath":"articles/2411.02704.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation","datePublished":"2024-11-05T00:00:00.000Z","dateModified":"2024-11-05T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.02704"}},{"title":"Multimodal Commonsense Knowledge Distillation for Visual Question Answering","date":"2024-11-05T00:00:00.000Z","tags":["Visual Question Answering","commonsense knowledge","ScienceQA dataset","Multimodal Large Language Models","teacher-student environment","Graph Convolutional Network","Visual Language Pretrained Models","knowledge distillation"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.02722v1","arx_url":"http://arxiv.org/abs/2411.02722v1","authors":["Shuo Yang","Siwen Luo","Soyeon Caren Han"],"affiliations_aligned":["","",""],"affiliations":[""],"problem":"VQA questions requiring external commonsense knowledge","solution":"graph-based multimodal commonsense knowledge distillation framework","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.555,"time":33300,"words":111},"slug":"2411.02722","path":"articles/2411.02722","filePath":"articles/2411.02722.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Multimodal Commonsense Knowledge Distillation for Visual Question Answering","datePublished":"2024-11-05T00:00:00.000Z","dateModified":"2024-11-05T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.02722"}},{"title":"Leveraging Large Language Models in Code Question Answering: Baselines and Issues","date":"2024-11-05T00:00:00.000Z","tags":["error analysis","Python","BERTScore F1","large language models","question answering","BLEU-4","dataset preprocessing","Exact Match","source code","grammar correction","BLEURT"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.03012v1","arx_url":"http://arxiv.org/abs/2411.03012v1","authors":["Georgy Andryushchenko","Vladimir Ivanov","Vladimir Makharev","Elizaveta Tukhtina","Aidar Valeev"],"affiliations_aligned":["Institute of Applied Physics, Russian Academy of Sciences","Moscow Institute of Physics and Technology","Kazan Federal University","National Research University Higher School of Economics","Kazan Federal University"],"affiliations":["National Research University Higher School of Economics","Institute of Applied Physics, Russian Academy of Sciences","Moscow Institute of Physics and Technology","Kazan Federal University"],"problem":"poor quality of public genuine question-answering datasets","solution":"fine-tuning a large language model on a unified dataset of questions and answers for Python code","score":7,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.045,"time":62700,"words":209},"slug":"2411.03012","path":"articles/2411.03012","filePath":"articles/2411.03012.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Leveraging Large Language Models in Code Question Answering: Baselines and Issues","datePublished":"2024-11-05T00:00:00.000Z","dateModified":"2024-11-05T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.03012"}},{"title":"MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning","date":"2024-11-05T00:00:00.000Z","tags":["financial evaluation system","candlestick charts","technical indicator charts","machine learning language models","financial models","Visual Question Answering","multimodal benchmarks"],"categories":["cs.CL","cs.CV"],"pdf_url":"http://arxiv.org/pdf/2411.03314v1","arx_url":"http://arxiv.org/abs/2411.03314v1","authors":["Ziliang Gan","Yu Lu","Dong Zhang","Haohan Li","Che Liu","Jian Liu","Ji Liu","Haipang Wu","Chaoyou Fu","Zenglin Xu","Rongjunchen Zhang","Yong Dai"],"affiliations_aligned":["HiThink Research","HiThink Research","HiThink Research","HiThink Research","Imperial College London","Beihang","HiThink Research","HiThink Research","Nanjing","Fudan University","HiThink Research","HiThink Research"],"affiliations":["Imperial College London","HiThink Research","Beihang","Nanjing","Fudan University"],"problem":"inadequate performance measurement of multimodal models in the financial domain","solution":"MME-Finance benchmark for multimodal finance evaluation","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.285,"time":77100,"words":257},"slug":"2411.03314","path":"articles/2411.03314","filePath":"articles/2411.03314.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning","datePublished":"2024-11-05T00:00:00.000Z","dateModified":"2024-11-05T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.03314"}},{"title":"SALSA: Soup-based Alignment Learning for Stronger Adaptation in RLHF","date":"2024-11-04T00:00:00.000Z","tags":["model robustness","out-of-distribution generalization","Kullback-Leibler divergence","Reinforcement Learning from Human Feedback","Large Language Models","policy optimization algorithms","benchmark validation","Proximal Policy Optimization","weight-space averaging","supervised fine-tuned models"],"categories":["cs.LG"],"pdf_url":"http://arxiv.org/pdf/2411.01798v1","arx_url":"http://arxiv.org/abs/2411.01798v1","authors":["Atoosa Chegini","Hamid Kazemi","Iman Mirzadeh","Dong Yin","Maxwell Horton","Moin Nabi","Mehrdad Farajtabar","Keivan Alizadeh"],"affiliations_aligned":["University of Maryland","Apple","Apple","Apple","Apple","Apple","Apple","Apple"],"affiliations":["University of Maryland","Apple"],"problem":"suboptimal alignment and performance in RLHF","solution":"Soup-based Alignment Learning for Stronger Adaptation","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.135,"time":68100,"words":227},"slug":"2411.01798","path":"articles/2411.01798","filePath":"articles/2411.01798.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"SALSA: Soup-based Alignment Learning for Stronger Adaptation in RLHF","datePublished":"2024-11-04T00:00:00.000Z","dateModified":"2024-11-04T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.01798"}},{"title":"Leveraging Label Semantics and Meta-Label Refinement for Multi-Label Question Classification","date":"2024-11-04T00:00:00.000Z","tags":["distribution imbalance","Math LLM","Retrieval Reranking","personalized learning","resource recommendation","semantic overlap","class center learning","F1 scores","meta-label refinement","educational resources","Precision@k","multi-label question classification","label semantics"],"categories":["cs.CL","cs.LG"],"pdf_url":"http://arxiv.org/pdf/2411.01841v1","arx_url":"http://arxiv.org/abs/2411.01841v1","authors":["Shi Dong","Xiaobei Niu","Rui Zhong","Zhifeng Wang","Mingzhang Zuo"],"affiliations_aligned":["Central China Normal University","Central China Normal University","Central China Normal University","Central China Normal University","Central China Normal University"],"affiliations":["Central China Normal University"],"problem":"challenges with semantic overlap and distribution imbalance of labels in the multi-label context","solution":"RR2QC, a novel Retrieval Reranking method for multi-label Question Classification","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.01,"time":60600,"words":202},"slug":"2411.01841","path":"articles/2411.01841","filePath":"articles/2411.01841.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Leveraging Label Semantics and Meta-Label Refinement for Multi-Label Question Classification","datePublished":"2024-11-04T00:00:00.000Z","dateModified":"2024-11-04T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.01841"}},{"title":"CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments","date":"2024-11-04T00:00:00.000Z","tags":["latent variables","Customer Relationship Management","customer service tasks","AI agents","rule-following","data distributions","agent capabilities","benchmarking","realistic tasks","function-calling","professional work environments"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.02305v1","arx_url":"http://arxiv.org/abs/2411.02305v1","authors":["Kung-Hsiang Huang","Akshara Prabhakar","Sidharth Dhawan","Yixin Mao","Huan Wang","Silvio Savarese","Caiming Xiong","Philippe Laban","Chien-Sheng Wu"],"affiliations_aligned":["Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research"],"affiliations":["Salesforce AI Research"],"problem":"lack of realistic benchmarks for evaluating AI agents in CRM systems","solution":"CRMArena benchmark for evaluating AI agents on realistic CRM tasks","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.025,"time":61500,"words":205},"slug":"2411.02305","path":"articles/2411.02305","filePath":"articles/2411.02305.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments","datePublished":"2024-11-04T00:00:00.000Z","dateModified":"2024-11-04T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.02305"}},{"title":"Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning","date":"2024-11-04T00:00:00.000Z","tags":["exact match accuracy","arithmetic expression datasets","chain-of-thought tokens","longest increasing subsequence datasets","performance improvement","integer multiplication task","entropy of intermediate representations","arithmetic reasoning","representation collapse","Decoder-only Transformers","dummy pause tokens","complex reasoning tasks","Sequential Variance-Covariance Regularization"],"categories":["cs.CL","cs.LG"],"pdf_url":"http://arxiv.org/pdf/2411.02344v1","arx_url":"http://arxiv.org/abs/2411.02344v1","authors":["Md Rifat Arefin","Gopeshh Subbaraj","Nicolas Gontier","Yann LeCun","Irina Rish","Ravid Shwartz-Ziv","Christopher Pal"],"affiliations_aligned":["Université de Montréal, Mila","Université de Montréal, Mila","ServiceNow","Meta FAIR","Université de Montréal, Mila","New York University","ServiceNow, Polytechnique Montreal"],"affiliations":["ServiceNow, Polytechnique Montreal","Université de Montréal, Mila","Meta FAIR","New York University","ServiceNow"],"problem":"representation collapse in intermediate layers limiting reasoning capabilities","solution":"Sequential Variance-Covariance Regularization (Seq-VCR)","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.76,"time":45600,"words":152},"slug":"2411.02344","path":"articles/2411.02344","filePath":"articles/2411.02344.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning","datePublished":"2024-11-04T00:00:00.000Z","dateModified":"2024-11-04T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.02344"}},{"title":"MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs","date":"2024-11-04T00:00:00.000Z","tags":["zero-shot reranking","hard negative mining","text-image queries","bi-encoder retriever","modality bias","information retrieval","large language models","multimodal retrieval"],"categories":["cs.CL","cs.CV","cs.AI","cs.LG","cs.IR"],"pdf_url":"http://arxiv.org/pdf/2411.02571v1","arx_url":"http://arxiv.org/abs/2411.02571v1","authors":["Sheng-Chieh Lin","Chankyu Lee","Mohammad Shoeybi","Jimmy Lin","Bryan Catanzaro","Wei Ping"],"affiliations_aligned":["NVIDIA","NVIDIA","NVIDIA","University of Waterloo","NVIDIA","NVIDIA"],"affiliations":["University of Waterloo","NVIDIA"],"problem":"modality bias in multimodal retrieval","solution":"modality-aware hard negative mining","score":9,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.31,"time":78600,"words":262},"slug":"2411.02571","path":"articles/2411.02571","filePath":"articles/2411.02571.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs","datePublished":"2024-11-04T00:00:00.000Z","dateModified":"2024-11-04T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.02571"}},{"title":"EcoAct: Economic Agent Determines When to Register What Action","date":"2024-11-03T00:00:00.000Z","tags":["reasoning procedures","Large Language Models","context optimization","agents","computational efficiency","tool registration"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.01643v1","arx_url":"http://arxiv.org/abs/2411.01643v1","authors":["Shaokun Zhang","Jieyu Zhang","Dujian Ding","Mirian Hipolito Garcia","Ankur Mallick","Daniel Madrigal","Menglin Xia","Victor Rühle","Qingyun Wu","Chi Wang"],"affiliations_aligned":["Pennsylvania State University","Microsoft","The University of Washington","Microsoft","Microsoft","Microsoft","Microsoft","Microsoft","Pennsylvania State University","Google DeepMind"],"affiliations":["Google DeepMind","Microsoft","The University of Washington","Pennsylvania State University"],"problem":"inefficient tool registration in LLM agents","solution":"EcoAct tool for selective tool registration","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.775,"time":46500,"words":155},"slug":"2411.01643","path":"articles/2411.01643","filePath":"articles/2411.01643.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"EcoAct: Economic Agent Determines When to Register What Action","datePublished":"2024-11-03T00:00:00.000Z","dateModified":"2024-11-03T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.01643"}},{"title":"Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models","date":"2024-11-03T00:00:00.000Z","tags":["instruction following","evaluation metrics","faithfulness","text generation","factual inaccuracies","hallucinations","citations","Large Language Models","coherence","trust in content","benchmark evaluations","completeness","auto-evaluators"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.02448v1","arx_url":"http://arxiv.org/abs/2411.02448v1","authors":["Aliyah R. Hsu","James Zhu","Zhichao Wang","Bin Bi","Shubham Mehrotra","Shiva K. Pentyala","Katherine Tan","Xiang-Bo Mao","Roshanak Omrani","Sougata Chaudhuri","Regunathan Radhakrishnan","Sitaram Asur","Claire Na Cheng","Bin Yu"],"affiliations_aligned":["UC Berkeley","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","Salesforce AI Platform","UC Berkeley"],"affiliations":["UC Berkeley","Salesforce AI Platform"],"problem":"rigorous evaluation of generated content quality","solution":"fine-tuned general-purpose LLM autoevaluators","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.83,"time":49800,"words":166},"slug":"2411.02448","path":"articles/2411.02448","filePath":"articles/2411.02448.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models","datePublished":"2024-11-03T00:00:00.000Z","dateModified":"2024-11-03T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.02448"}},{"title":"Visual Fourier Prompt Tuning","date":"2024-11-02T00:00:00.000Z","tags":["finetuning","empirical results","Visual prompt tuning","parameter-efficient finetuning","Fast Fourier Transform","spatial domain","performance degradation","frequency domain","state-of-the-art baselines","prompt embeddings","vision Transformer","datasets"],"categories":["cs.CV","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.01327v1","arx_url":"http://arxiv.org/abs/2411.01327v1","authors":["Runjia Zeng","Cheng Han","Qifan Wang","Chunshu Wu","Tong Geng","Lifu Huang","Ying Nian Wu","Dongfang Liu"],"affiliations_aligned":["Rochester Institute of Technology","University of Missouri - Kansas City","Meta AI","University of Rochester","University of Rochester","Virginia Tech","University of California, Los Angeles","Rochester Institute of Technology"],"affiliations":["Rochester Institute of Technology","Meta AI","University of Rochester","University of Missouri - Kansas City","Virginia Tech","University of California, Los Angeles"],"problem":"performance degradation due to dataset disparity","solution":"Visual Fourier Prompt Tuning method","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.93,"time":55800,"words":186},"slug":"2411.01327","path":"articles/2411.01327","filePath":"articles/2411.01327.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Visual Fourier Prompt Tuning","datePublished":"2024-11-02T00:00:00.000Z","dateModified":"2024-11-02T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.01327"}},{"title":"Online and Offline Evaluations of Collaborative Filtering and Content Based Recommender Systems","date":"2024-11-02T00:00:00.000Z","tags":["e-commerce","hybrid approaches","hit-rate@k","A/B testing","user-based recommendations","news broadcasting","offline evaluations","popularity bias","manual evaluation","item-based recommendations","collaborative filtering","nDCG","digital publishing","user satisfaction","content-based methods","algorithms","information retrieval","trend-based methods","media streaming","Persian language","click-through rate","online evaluations","datasets","accuracy metrics","recommender systems","cold-start"],"categories":["cs.CL","cs.IR","cs.AI","cs.LG"],"pdf_url":"http://arxiv.org/pdf/2411.01354v1","arx_url":"http://arxiv.org/abs/2411.01354v1","authors":["Ali Elahi","Armin Zirak"],"affiliations_aligned":["University of Illinois at Chicago, Chicago, Illinois, USA","University of Illinois at Chicago, Chicago, Illinois, USA"],"affiliations":["University of Illinois at Chicago, Chicago, Illinois, USA"],"problem":"user satisfaction complexity in recommender systems","solution":"comparative analysis of evaluation methods for recommender systems","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.19,"time":71400,"words":238},"slug":"2411.01354","path":"articles/2411.01354","filePath":"articles/2411.01354.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Online and Offline Evaluations of Collaborative Filtering and Content Based Recommender Systems","datePublished":"2024-11-02T00:00:00.000Z","dateModified":"2024-11-02T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.01354"}},{"title":"Self-Evolved Reward Learning for LLMs","date":"2024-11-01T00:00:00.000Z","tags":["biases","human preferences","training data","Reinforcement Learning from Human Feedback","reward model","self-feedback","large language models","experiments","language models","datasets"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.00418v1","arx_url":"http://arxiv.org/abs/2411.00418v1","authors":["Chenghua Huang","Zhizhen Fan","Lu Wang","Fangkai Yang","Pu Zhao","Zeqi Lin","Qingwei Lin","Dongmei Zhang","Saravan Rajmohan","Qi Zhang"],"affiliations_aligned":["School of Computer Science, Fudan University","School of Computer Science, Peking University","Microsoft","Microsoft","Microsoft","Microsoft","Microsoft","Microsoft","Microsoft","Microsoft"],"affiliations":["Microsoft","School of Computer Science, Fudan University","School of Computer Science, Peking University"],"problem":"training a reliable reward model","solution":"Self-Evolved Reward Learning","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.825,"time":49500,"words":165},"slug":"2411.00418","path":"articles/2411.00418","filePath":"articles/2411.00418.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Self-Evolved Reward Learning for LLMs","datePublished":"2024-11-01T00:00:00.000Z","dateModified":"2024-11-01T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.00418"}},{"title":"DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems","date":"2024-11-01T00:00:00.000Z","tags":["entity types","domain-specific knowledge","agent modeling approaches","MultiWOZ benchmark","multi-agent conversational system","task-oriented dialogue systems","dialogue inform rate","Large Language Models","fine-tuned models","MultiWOZ dataset","multi-domain systems","dialog manager agent","annotator discrepancies","success rate","user intents"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.00427v1","arx_url":"http://arxiv.org/abs/2411.00427v1","authors":["Aman Gupta","Anirudh Ravichandran","Ziji Zhang","Swair Shah","Anurag Beniwal","Narayanan Sadagopan"],"affiliations_aligned":["Carnegie Mellon University","Amazon","Amazon","Amazon","Amazon","Amazon"],"affiliations":["Carnegie Mellon University","Amazon"],"problem":"developing effective multi-domain systems","solution":"DARD (Domain Assigned Response Delegation)","score":7,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.895,"time":53700,"words":179},"slug":"2411.00427","path":"articles/2411.00427","filePath":"articles/2411.00427.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems","datePublished":"2024-11-01T00:00:00.000Z","dateModified":"2024-11-01T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.00427"}},{"title":"Interpretable Language Modeling via Induction-head Ngram Models","date":"2024-10-31T00:00:00.000Z","tags":["large language models","Induction-head ngram models","interpretability","efficiency","natural-language neuroscience","next-word prediction","language selectivity","speculative decoding","neural similarity metric","fMRI response prediction"],"categories":["cs.CL","cs.AI","cs.LG"],"pdf_url":"http://arxiv.org/pdf/2411.00066v1","arx_url":"http://arxiv.org/abs/2411.00066v1","authors":["Eunji Kim","Sriya Mantena","Weiwei Yang","Chandan Singh","Sungroh Yoon","Jianfeng Gao"],"affiliations_aligned":["Department of Electrical and Computer Engineering, Seoul National University","Stanford University","Microsoft Research","Microsoft Research","Interdisciplinary Program in Artificial Intelligence, Seoul National University","Microsoft Research"],"affiliations":["Microsoft Research","Stanford University","Department of Electrical and Computer Engineering, Seoul National University","Interdisciplinary Program in Artificial Intelligence, Seoul National University"],"problem":"demand for interpretability and efficiency in language models","solution":"Induction-head ngram models","score":7,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.9,"time":54000,"words":180},"slug":"2411.00066","path":"articles/2411.00066","filePath":"articles/2411.00066.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Interpretable Language Modeling via Induction-head Ngram Models","datePublished":"2024-10-31T00:00:00.000Z","dateModified":"2024-10-31T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.00066"}},{"title":"RSL-SQL: Robust Schema Linking in Text-to-SQL Generation","date":"2024-10-31T00:00:00.000Z","tags":["DeepSeek","large language models","contextual information augmentation","Text-to-SQL generation","computational overhead","schema linking","execution accuracy","ablation studies","multi-turn self-correction"],"categories":["cs.CL","cs.AI","cs.DB"],"pdf_url":"http://arxiv.org/pdf/2411.00073v1","arx_url":"http://arxiv.org/abs/2411.00073v1","authors":["Zhenbiao Cao","Yuanlei Zheng","Zhihao Fan","Xiaojin Zhang","Wei Chen"],"affiliations_aligned":["Huazhong University of Science and Technology","Huazhong University of Science and Technology","Alibaba Inc.","Huazhong University of Science and Technology","Huazhong University of Science and Technology"],"affiliations":["Huazhong University of Science and Technology","Alibaba Inc."],"problem":"risks in schema linking for Text-to-SQL generation","solution":"RSL-SQL framework","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.925,"time":55500,"words":185},"slug":"2411.00073","path":"articles/2411.00073","filePath":"articles/2411.00073.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"RSL-SQL: Robust Schema Linking in Text-to-SQL Generation","datePublished":"2024-10-31T00:00:00.000Z","dateModified":"2024-10-31T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.00073"}},{"title":"JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking","date":"2024-10-31T00:00:00.000Z","tags":["document retrieval","reasoning-intensive tasks","large language models","query analysis","BRIGHT benchmark","BEIR benchmark","ablation studies","zero-shot generalization","reranking","document analysis","retrieval-augmented generation","relevance judgment"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.00142v1","arx_url":"http://arxiv.org/abs/2411.00142v1","authors":["Tong Niu","Shafiq Joty","Ye Liu","Caiming Xiong","Yingbo Zhou","Semih Yavuz"],"affiliations_aligned":["Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research","Salesforce AI Research"],"affiliations":["Salesforce AI Research"],"problem":"lack of nuanced analysis in judging document relevance","solution":"JudgeRank, a novel agentic reranker","score":8,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.88,"time":52800,"words":176},"slug":"2411.00142","path":"articles/2411.00142","filePath":"articles/2411.00142.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking","datePublished":"2024-10-31T00:00:00.000Z","dateModified":"2024-10-31T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.00142"}},{"title":"ACC-Debate: An Actor-Critic Approach to Multi-Agent Debate","date":"2024-10-30T00:00:00.000Z","tags":["multi-agent debate","debate frameworks","benchmark performance","large language models","model efficacy","actor-critic approach","collaborative behaviors"],"categories":["cs.CL","cs.AI"],"pdf_url":"http://arxiv.org/pdf/2411.00053v2","arx_url":"http://arxiv.org/abs/2411.00053v2","authors":["Andrew Estornell","Jean-Francois Ton","Yuanshun Yao","Yang Liu","Jean-François Ton"],"affiliations_aligned":["ByteDance Research","","Meta GenAI","University of California, Santa Cruz","ByteDance Research"],"affiliations":["","Meta GenAI","University of California, Santa Cruz","ByteDance Research"],"problem":"limitations of current debate frameworks","solution":"ACC-Debate learning framework","score":6,"type":"Blog","readingTime":{"text":"1 min read","minutes":0.615,"time":36900,"words":123},"slug":"2411.00053","path":"articles/2411.00053","filePath":"articles/2411.00053.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"ACC-Debate: An Actor-Critic Approach to Multi-Agent Debate","datePublished":"2024-10-30T00:00:00.000Z","dateModified":"2024-10-30T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.00053"}},{"title":"Enhancing Retrieval Performance: An Ensemble Approach For Hard Negative Mining","date":"2024-10-18T00:00:00.000Z","tags":["Retrieval-Augmented Generation","Reasoning and Action Agents","cross-encoder models","retrieval performance","enterprise dataset","negative pairs","ranking models","hard negative mining","information retrieval"],"categories":["cs.CL","cs.IR","cs.AI","cs.LG"],"pdf_url":"http://arxiv.org/pdf/2411.02404v1","arx_url":"http://arxiv.org/abs/2411.02404v1","authors":["Hansa Meghwani"],"affiliations_aligned":[""],"affiliations":[""],"problem":"identifying suitable negative pairs from a vast pool of documents","solution":"robust hard negative mining technique for efficient training of cross-encoder re-rank models","score":6,"type":"Blog","readingTime":{"text":"2 min read","minutes":1.275,"time":76500,"words":255},"slug":"2411.02404","path":"articles/2411.02404","filePath":"articles/2411.02404.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Enhancing Retrieval Performance: An Ensemble Approach For Hard Negative Mining","datePublished":"2024-10-18T00:00:00.000Z","dateModified":"2024-10-18T00:00:00.000Z","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/2411.02404"}},{"title":"Introducing Multi-part Posts with Nested Routing","date":"2021-05-02T00:00:00.000Z","tags":["multi-author","next-js","feature"],"categories":[],"draft":false,"summary":"The blog template supports posts in nested sub-folders. This can be used to group posts of similar content e.g. a multi-part course. This post is itself an example of a nested route!","pdf_url":"https://arxiv.org/pdf/2411.03163","arx_url":"https://arxiv.org/abs/2411.03163","authors":[],"affiliations_aligned":[],"affiliations":[],"type":"Blog","readingTime":{"text":"1 min read","minutes":0.845,"time":50700,"words":169},"slug":"nested-route/introducing-multi-part-posts-with-nested-routing","path":"articles/nested-route/introducing-multi-part-posts-with-nested-routing","filePath":"articles/nested-route/introducing-multi-part-posts-with-nested-routing.mdx","toc":[{"value":"Nested Routes","url":"#nested-routes","depth":1},{"value":"How","url":"#how","depth":2},{"value":"Use Cases","url":"#use-cases","depth":2},{"value":"Note","url":"#note","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Introducing Multi-part Posts with Nested Routing","datePublished":"2021-05-02T00:00:00.000Z","dateModified":"2021-05-02T00:00:00.000Z","description":"The blog template supports posts in nested sub-folders. This can be used to group posts of similar content e.g. a multi-part course. This post is itself an example of a nested route!","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/nested-route/introducing-multi-part-posts-with-nested-routing"}},{"title":"Sample .md file","date":"2016-03-08T00:00:00.000Z","tags":["markdown","code","features"],"categories":[],"draft":false,"summary":"Example of a markdown file with code blocks and syntax highlighting","pdf_url":"https://arxiv.org/pdf/2411.00000","arx_url":"https://arxiv.org/abs/2411.00000","authors":["Xin Wang","Xinyi Bai"],"affiliations_aligned":[],"affiliations":["Henan Institute of Technology, China","Henan Institute of Technology, China"],"type":"Blog","readingTime":{"text":"1 min read","minutes":0.595,"time":35700,"words":119},"slug":"nested-route/code-sample","path":"articles/nested-route/code-sample","filePath":"articles/nested-route/code-sample.mdx","toc":[{"value":"Inline Highlighting","url":"#inline-highlighting","depth":2},{"value":"Code Blocks","url":"#code-blocks","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Sample .md file","datePublished":"2016-03-08T00:00:00.000Z","dateModified":"2016-03-08T00:00:00.000Z","description":"Example of a markdown file with code blocks and syntax highlighting","image":"/static/images/twitter-card.png","url":"https://ai-heap.com/articles/nested-route/code-sample"}}]